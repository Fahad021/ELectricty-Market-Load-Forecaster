{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AIL</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>just_date</th>\n",
       "      <th>day</th>\n",
       "      <th>hour_x_day</th>\n",
       "      <th>sin.day</th>\n",
       "      <th>cos.day</th>\n",
       "      <th>sin.hour</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_ftmcmry</th>\n",
       "      <th>wind_ftmcmry</th>\n",
       "      <th>temp_lthbrg</th>\n",
       "      <th>wind_lthbrg</th>\n",
       "      <th>temp_mdcnht</th>\n",
       "      <th>wind_mdcnht</th>\n",
       "      <th>temp_rddr</th>\n",
       "      <th>wind_rddr</th>\n",
       "      <th>temp_slvlk</th>\n",
       "      <th>wind_slvlk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>10008.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.1</td>\n",
       "      <td>11</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>9868.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>9736.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>9597.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-14.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18505</th>\n",
       "      <td>2021-02-10 19:00:00</td>\n",
       "      <td>11485.0</td>\n",
       "      <td>18524</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>779</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18506</th>\n",
       "      <td>2021-02-10 20:00:00</td>\n",
       "      <td>11364.0</td>\n",
       "      <td>18525</td>\n",
       "      <td>20</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>820</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18507</th>\n",
       "      <td>2021-02-10 21:00:00</td>\n",
       "      <td>11195.0</td>\n",
       "      <td>18526</td>\n",
       "      <td>21</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>861</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>2021-02-10 22:00:00</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>18527</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>902</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18509</th>\n",
       "      <td>2021-02-10 23:00:00</td>\n",
       "      <td>10839.0</td>\n",
       "      <td>18528</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>943</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18510 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datetime      AIL  trend  hour_of_day   just_date  day  \\\n",
       "0      2019-01-01 00:00:00  10008.0      1            0  2019-01-01    1   \n",
       "1      2019-01-01 01:00:00   9868.0      2            1  2019-01-01    1   \n",
       "2      2019-01-01 02:00:00   9736.0      3            2  2019-01-01    1   \n",
       "3      2019-01-01 03:00:00   9597.0      4            3  2019-01-01    1   \n",
       "4      2019-01-01 04:00:00   9530.0      5            4  2019-01-01    1   \n",
       "...                    ...      ...    ...          ...         ...  ...   \n",
       "18505  2021-02-10 19:00:00  11485.0  18524           19  2021-02-10   41   \n",
       "18506  2021-02-10 20:00:00  11364.0  18525           20  2021-02-10   41   \n",
       "18507  2021-02-10 21:00:00  11195.0  18526           21  2021-02-10   41   \n",
       "18508  2021-02-10 22:00:00  10961.0  18527           22  2021-02-10   41   \n",
       "18509  2021-02-10 23:00:00  10839.0  18528           23  2021-02-10   41   \n",
       "\n",
       "       hour_x_day   sin.day   cos.day  sin.hour  ...  temp_ftmcmry  \\\n",
       "0               0  0.017213  0.999852  0.000000  ...         -18.1   \n",
       "1               1  0.017213  0.999852  0.258819  ...         -17.0   \n",
       "2               2  0.017213  0.999852  0.500000  ...         -15.2   \n",
       "3               3  0.017213  0.999852  0.707107  ...         -13.2   \n",
       "4               4  0.017213  0.999852  0.866025  ...         -11.5   \n",
       "...           ...       ...       ...       ...  ...           ...   \n",
       "18505         779  0.648630  0.761104 -0.965926  ...         -29.0   \n",
       "18506         820  0.648630  0.761104 -0.866025  ...         -30.0   \n",
       "18507         861  0.648630  0.761104 -0.707107  ...         -31.0   \n",
       "18508         902  0.648630  0.761104 -0.500000  ...         -32.0   \n",
       "18509         943  0.648630  0.761104 -0.258819  ...         -33.0   \n",
       "\n",
       "       wind_ftmcmry  temp_lthbrg  wind_lthbrg  temp_mdcnht  wind_mdcnht  \\\n",
       "0                11        -11.8          NaN        -12.4          NaN   \n",
       "1                 9        -10.7          NaN        -12.5          NaN   \n",
       "2                 8         -8.5          NaN        -11.8          NaN   \n",
       "3                12         -6.7          NaN        -10.6          NaN   \n",
       "4                 9         -3.6          NaN         -8.1          NaN   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "18505            20        -27.0         20.0        -27.0         20.0   \n",
       "18506            20        -28.0         20.0        -28.0         20.0   \n",
       "18507            10        -31.0         10.0        -29.0         10.0   \n",
       "18508            10        -31.0         10.0        -29.0         10.0   \n",
       "18509            10        -32.0         10.0        -30.0         10.0   \n",
       "\n",
       "       temp_rddr  wind_rddr  temp_slvlk  wind_slvlk  \n",
       "0          -15.2       11.0       -14.4         8.0  \n",
       "1          -13.3        5.0       -13.6         5.0  \n",
       "2          -11.8       13.0       -12.9         5.0  \n",
       "3          -10.2       14.0       -14.1         5.0  \n",
       "4           -8.8       17.0       -12.2         5.0  \n",
       "...          ...        ...         ...         ...  \n",
       "18505      -30.0       20.0       -26.0        10.0  \n",
       "18506      -31.0       20.0       -27.0        10.0  \n",
       "18507      -32.0       10.0       -28.0        10.0  \n",
       "18508      -33.0       10.0       -29.0        10.0  \n",
       "18509      -34.0       10.0       -30.0        10.0  \n",
       "\n",
       "[18510 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('new_training_data_v7_2019_2020_feb_13_20201.csv').iloc[:,1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'AIL', 'trend', 'hour_of_day', 'just_date', 'day',\n",
       "       'hour_x_day', 'sin.day', 'cos.day', 'sin.hour', 'cos.hour', 'sin.trend',\n",
       "       'cos.trend', 'weekend', 'month', 'year', 'sunlight_avaialbility',\n",
       "       'AIL_previous_hour', 'AIL_24h_lagged', 'AIL_2day_lagged',\n",
       "       'AIL_3day_lagged', 'AIL_4day_lagged', 'AIL_5day_lagged',\n",
       "       'AIL_6day_lagged', 'AIL_oneweek_lagged', 'temp_calgary', 'wind_calgary',\n",
       "       'temp_edmonton', 'wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
       "       'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', 'temp_rddr',\n",
       "       'wind_rddr', 'temp_slvlk', 'wind_slvlk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_calgary_lag1'] = df['temp_calgary'].shift(1)\n",
    "df['temp_calgary_lag2'] = df['temp_calgary'].shift(2)\n",
    "df['temp_calgary_lag3'] = df['temp_calgary'].shift(3)\n",
    "\n",
    "df['temp_calgary_lag1_squared'] =  df['temp_calgary_lag1']**2\n",
    "df['temp_calgary_lag2_squared'] =  df['temp_calgary_lag2']**2\n",
    "df['temp_calgary_lag3_squared'] =  df['temp_calgary_lag3']**2\n",
    "\n",
    "df['temp_calgary_lag1_cube'] =  df['temp_calgary']**3\n",
    "df['temp_calgary_lag2_cube'] =  df['temp_calgary']**3\n",
    "df['temp_calgary_lag3_cube'] =  df['temp_calgary']**3\n",
    "\n",
    "#------------\n",
    "df['temp_edmonton_lag1'] = df['temp_edmonton'].shift(1)\n",
    "df['temp_edmonton_lag2'] = df['temp_edmonton'].shift(2)\n",
    "df['temp_edmonton_lag3'] = df['temp_edmonton'].shift(3)\n",
    "\n",
    "df['temp_edmonton_lag1_squared'] =  df['temp_edmonton_lag1']**2\n",
    "df['temp_edmonton_lag2_squared'] =  df['temp_edmonton_lag2']**2\n",
    "df['temp_edmonton_lag3_squared'] =  df['temp_edmonton_lag3']**2\n",
    "\n",
    "df['temp_edmonton_lag1_cube'] =  df['temp_edmonton']**3\n",
    "df['temp_edmonton_lag2_cube'] =  df['temp_edmonton']**3\n",
    "df['temp_edmonton_lag3_cube'] =  df['temp_edmonton']**3\n",
    "\n",
    "#-------\n",
    "df['hour_temp_calgary']      = df['hour_of_day'] * df['temp_calgary']\n",
    "df['month_temp_calgary']     = df['month'] * df['temp_calgary']\n",
    "\n",
    "df['hour_temp_calgary_lag1'] = df['hour_of_day']* df['temp_calgary_lag1'] \n",
    "df['hour_temp_calgary_lag2'] = df['hour_of_day']* df['temp_calgary_lag2'] \n",
    "df['hour_temp_calgary_lag3'] = df['hour_of_day']* df['temp_calgary_lag3']\n",
    "\n",
    "df['month_temp_calgary_lag1'] = df['month']* df['temp_calgary_lag1'] \n",
    "df['month_temp_calgary_lag2'] = df['month']* df['temp_calgary_lag2'] \n",
    "df['month_temp_calgary_lag3'] = df['month']* df['temp_calgary_lag3']\n",
    "\n",
    "df['hour_temp_calgary_lag1_sqd'] = df['hour_of_day']* df['temp_calgary_lag1_squared'] \n",
    "df['hour_temp_calgary_lag2_sqd'] = df['hour_of_day']* df['temp_calgary_lag2_squared'] \n",
    "df['hour_temp_calgary_lag3_sqd'] = df['hour_of_day']* df['temp_calgary_lag3_squared']\n",
    "\n",
    "df['month_temp_calgary_lag1_cube'] = df['month']* df['temp_calgary_lag1_squared'] \n",
    "df['month_temp_calgary_lag2_cube'] = df['month']* df['temp_calgary_lag2_squared'] \n",
    "df['month_temp_calgary_lag3_cube'] = df['month']* df['temp_calgary_lag3_squared']\n",
    "\n",
    "#-----------\n",
    "df['hour_temp_edmonton']  = df['hour_of_day'] * df['temp_edmonton']\n",
    "df['month_temp_edmonton'] = df['month'] * df['temp_edmonton']\n",
    "\n",
    "df['hour_temp_edmonton_lag1'] = df['hour_of_day']* df['temp_edmonton_lag1'] \n",
    "df['hour_temp_edmonton_lag2'] = df['hour_of_day']* df['temp_edmonton_lag2'] \n",
    "df['hour_temp_edmonton_lag3'] = df['hour_of_day']* df['temp_edmonton_lag3']\n",
    "\n",
    "df['month_temp_edmonton_lag1'] = df['month']* df['temp_edmonton_lag1'] \n",
    "df['month_temp_edmonton_lag2'] = df['month']* df['temp_edmonton_lag2'] \n",
    "df['month_temp_edmonton_lag3'] = df['month']* df['temp_edmonton_lag3']\n",
    "\n",
    "df['hour_temp_edmonton_lag1_sqd'] = df['hour_of_day']* df['temp_edmonton_lag1_squared'] \n",
    "df['hour_temp_edmonton_lag2_sqd'] = df['hour_of_day']* df['temp_edmonton_lag2_squared'] \n",
    "df['hour_temp_edmonton_lag3_sqd'] = df['hour_of_day']* df['temp_edmonton_lag3_squared']\n",
    "\n",
    "df['month_temp_edmonton_lag1_cube'] = df['month']* df['temp_edmonton_lag1_squared'] \n",
    "df['month_temp_edmonton_lag2_cube'] = df['month']* df['temp_edmonton_lag2_squared'] \n",
    "df['month_temp_edmonton_lag3_cube'] = df['month']* df['temp_edmonton_lag3_squared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'AIL', 'trend', 'hour_of_day', 'just_date', 'day',\n",
       "       'hour_x_day', 'sin.day', 'cos.day', 'sin.hour', 'cos.hour', 'sin.trend',\n",
       "       'cos.trend', 'weekend', 'month', 'year', 'sunlight_avaialbility',\n",
       "       'AIL_previous_hour', 'AIL_24h_lagged', 'AIL_2day_lagged',\n",
       "       'AIL_3day_lagged', 'AIL_4day_lagged', 'AIL_5day_lagged',\n",
       "       'AIL_6day_lagged', 'AIL_oneweek_lagged', 'temp_calgary', 'wind_calgary',\n",
       "       'temp_edmonton', 'wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
       "       'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', 'temp_rddr',\n",
       "       'wind_rddr', 'temp_slvlk', 'wind_slvlk', 'temp_calgary_lag1',\n",
       "       'temp_calgary_lag2', 'temp_calgary_lag3', 'temp_calgary_lag1_squared',\n",
       "       'temp_calgary_lag2_squared', 'temp_calgary_lag3_squared',\n",
       "       'temp_calgary_lag1_cube', 'temp_calgary_lag2_cube',\n",
       "       'temp_calgary_lag3_cube', 'temp_edmonton_lag1', 'temp_edmonton_lag2',\n",
       "       'temp_edmonton_lag3', 'temp_edmonton_lag1_squared',\n",
       "       'temp_edmonton_lag2_squared', 'temp_edmonton_lag3_squared',\n",
       "       'temp_edmonton_lag1_cube', 'temp_edmonton_lag2_cube',\n",
       "       'temp_edmonton_lag3_cube', 'hour_temp_calgary', 'month_temp_calgary',\n",
       "       'hour_temp_calgary_lag1', 'hour_temp_calgary_lag2',\n",
       "       'hour_temp_calgary_lag3', 'month_temp_calgary_lag1',\n",
       "       'month_temp_calgary_lag2', 'month_temp_calgary_lag3',\n",
       "       'hour_temp_calgary_lag1_sqd', 'hour_temp_calgary_lag2_sqd',\n",
       "       'hour_temp_calgary_lag3_sqd', 'month_temp_calgary_lag1_cube',\n",
       "       'month_temp_calgary_lag2_cube', 'month_temp_calgary_lag3_cube',\n",
       "       'hour_temp_edmonton', 'month_temp_edmonton', 'hour_temp_edmonton_lag1',\n",
       "       'hour_temp_edmonton_lag2', 'hour_temp_edmonton_lag3',\n",
       "       'month_temp_edmonton_lag1', 'month_temp_edmonton_lag2',\n",
       "       'month_temp_edmonton_lag3', 'hour_temp_edmonton_lag1_sqd',\n",
       "       'hour_temp_edmonton_lag2_sqd', 'hour_temp_edmonton_lag3_sqd',\n",
       "       'month_temp_edmonton_lag1_cube', 'month_temp_edmonton_lag2_cube',\n",
       "       'month_temp_edmonton_lag3_cube'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7967144544695388, test loss: 1.1972604674704894\n",
      "train loss: 0.41546637540778697, test loss: 1.1653638926872876                   \n",
      "train loss: 0.5782626118686611, test loss: 1.173204686746299                     \n",
      "train loss: 0.9540301727591655, test loss: 1.176061117707571                     \n",
      "train loss: 1.1477651249509906, test loss: 1.2307023972793005                    \n",
      "train loss: 0.80946246717688, test loss: 1.16066902034491                        \n",
      "train loss: 0.852767561723807, test loss: 1.1590701671112633                     \n",
      "train loss: 0.2534636690532257, test loss: 1.1771353301793848                    \n",
      "train loss: 0.4748412901324277, test loss: 1.188564650874767                     \n",
      "train loss: 0.6368799339092941, test loss: 1.196968009519399                     \n",
      "train loss: 0.4436814809257069, test loss: 1.1325878385591541                     \n",
      "train loss: 0.6741807574314604, test loss: 1.1476708518760415                     \n",
      "train loss: 0.7188146528335455, test loss: 1.1361063814414545                     \n",
      "train loss: 0.7295068050603897, test loss: 1.1304028687253551                     \n",
      "train loss: 0.7672818322164902, test loss: 1.1207039606403508                     \n",
      "train loss: 0.22310203774216442, test loss: 1.2345745627584195                    \n",
      "train loss: 0.6693620050867565, test loss: 1.1634279575195376                     \n",
      "train loss: 0.4424422167683493, test loss: 1.2444207266299703                     \n",
      "train loss: 0.7836198832256818, test loss: 1.1726864886310002                     \n",
      "train loss: 0.4270594122920083, test loss: 1.120307041155855                      \n",
      "train loss: 0.20832126149364968, test loss: 1.2025470199142867                    \n",
      "train loss: 0.8412825948672721, test loss: 1.1287431396708623                    \n",
      "train loss: 0.4028208611776659, test loss: 1.2657223169148477                    \n",
      "train loss: 0.3637190740506536, test loss: 1.1781332160445206                    \n",
      "train loss: 0.2430898771270946, test loss: 1.1715089329582513                    \n",
      "train loss: 0.8141097038507693, test loss: 1.1591533970913759                    \n",
      "train loss: 0.8380498856636207, test loss: 1.1255346074715833                    \n",
      "train loss: 0.6928008937826333, test loss: 1.1809378366098002                    \n",
      "train loss: 1.2894151526339628, test loss: 1.5822112848626633                    \n",
      "train loss: 0.4732051270327505, test loss: 1.153758325386668                     \n",
      "train loss: 0.5251480652149734, test loss: 1.167001402115016                     \n",
      "train loss: 0.2540478166457149, test loss: 1.2317050601701334                    \n",
      "train loss: 0.47663916692445507, test loss: 1.1641603573322021                   \n",
      "train loss: 0.5398054045638957, test loss: 1.1863192840428476                    \n",
      "train loss: 0.997077164083126, test loss: 1.1978421938322856                     \n",
      "train loss: 0.9242485682399567, test loss: 1.1523865500059844                    \n",
      "train loss: 0.5337203417723226, test loss: 1.1683975255308832                    \n",
      "train loss: 0.7304398611109448, test loss: 1.1571752170218235                    \n",
      "train loss: 0.3645234543430513, test loss: 1.1196094472565272                    \n",
      "train loss: 0.5584769964525539, test loss: 1.177057693408767                      \n",
      "train loss: 0.13274601880103137, test loss: 1.3047686563289564                    \n",
      "train loss: 0.2719525978957642, test loss: 1.1494064179905399                     \n",
      "train loss: 0.500411770519068, test loss: 1.1826752999376526                      \n",
      "train loss: 0.5821847285909066, test loss: 1.1909365995938817                     \n",
      "train loss: 0.6627847567999742, test loss: 1.2263906176472814                     \n",
      "train loss: 0.3256499900582983, test loss: 1.1984666259855299                     \n",
      "train loss: 0.5956802151302695, test loss: 1.2011009857797335                     \n",
      "train loss: 0.17333245488090218, test loss: 1.2490120370878721                    \n",
      "train loss: 0.38513622501340267, test loss: 1.1818537231749027                    \n",
      "train loss: 0.6156099391430258, test loss: 1.1578989930966321                     \n",
      "train loss: 0.5736344409385886, test loss: 1.1751481344569294                     \n",
      "train loss: 0.5113850379752806, test loss: 1.1510863813509207                     \n",
      "train loss: 0.3790068334222089, test loss: 1.185061706452434                      \n",
      "train loss: 0.29801249432028665, test loss: 1.1649494384154728                    \n",
      "train loss: 0.8970565089964824, test loss: 1.1766431735970104                     \n",
      "train loss: 0.5063209384433328, test loss: 1.2418041740792842                     \n",
      "train loss: 0.6092104719895772, test loss: 1.1966943884833767                     \n",
      "train loss: 0.24696424580945386, test loss: 1.215076953282002                     \n",
      "train loss: 0.6989862550586413, test loss: 1.171733996224138                      \n",
      "train loss: 0.4453661431060486, test loss: 1.1944797915226966                     \n",
      "train loss: 0.4638390983711697, test loss: 1.2177102964111182                     \n",
      "train loss: 0.2710792935618516, test loss: 1.3027866958857888                     \n",
      "train loss: 1.1011379918177369, test loss: 1.1950302131405106                     \n",
      "train loss: 0.5560164279612726, test loss: 1.2084924581105654                     \n",
      "train loss: 0.3409103285228412, test loss: 1.1820940277835266                     \n",
      "train loss: 0.8749833687635213, test loss: 1.1657794400673152                     \n",
      "train loss: 0.7667154524026716, test loss: 1.1391618403733972                     \n",
      "train loss: 0.4596529063110564, test loss: 1.1568354840983293                     \n",
      "train loss: 0.6980837844320276, test loss: 1.1696992072045946                     \n",
      "train loss: 0.6332957912168445, test loss: 1.1219875377939221                     \n",
      "train loss: 0.3423875490333355, test loss: 1.1744177828665805                     \n",
      "train loss: 0.2073194685152766, test loss: 1.2449135709200634                     \n",
      "train loss: 0.4129623051923279, test loss: 1.2031952971085502                     \n",
      "train loss: 0.40737692894903776, test loss: 1.163822927309973                     \n",
      "train loss: 0.3880685071224433, test loss: 1.1813160780132277                     \n",
      "train loss: 0.9489692486972638, test loss: 1.167932005146635                      \n",
      "train loss: 0.46564481047766176, test loss: 1.1385838454235488                    \n",
      "train loss: 0.9048701894948034, test loss: 1.1461516088369776                     \n",
      "train loss: 0.8905719961753371, test loss: 1.1457928453626705                     \n",
      "train loss: 0.8557377079306899, test loss: 1.1666698475217132                     \n",
      "train loss: 0.5191897164583955, test loss: 1.179856189317355                      \n",
      "train loss: 0.4023286182539335, test loss: 1.2423536480007265                     \n",
      "train loss: 0.5211661169742031, test loss: 1.2467593371432024                     \n",
      "train loss: 0.42505385109172444, test loss: 1.1624284494753274                    \n",
      "train loss: 0.1524876717426953, test loss: 1.283410633541457                      \n",
      "train loss: 0.6331384066450315, test loss: 1.1782936951712273                     \n",
      "train loss: 0.315577092513302, test loss: 1.1955487493807402                      \n",
      "train loss: 0.17240457625097724, test loss: 1.2040145990687394                    \n",
      "train loss: 0.26019304561156587, test loss: 1.1847343766444631                    \n",
      "train loss: 0.4986135391032067, test loss: 1.19254308141619                       \n",
      "train loss: 1.040845405463306, test loss: 1.1646083187215295                      \n",
      "train loss: 0.3951414961830392, test loss: 1.2312460755324701                     \n",
      "train loss: 0.5154971245470876, test loss: 1.189066583728949                      \n",
      "train loss: 0.5068998323293779, test loss: 1.1745105387627097                     \n",
      "train loss: 0.37838619877178514, test loss: 1.2050608221879167                    \n",
      "train loss: 0.8186280834198194, test loss: 1.194330000928044                      \n",
      "train loss: 0.3750119982799217, test loss: 1.2005010314919469                     \n",
      "train loss: 0.7822422962344286, test loss: 1.1473396137540477                     \n",
      "train loss: 0.27487662974140376, test loss: 1.2108910619629412                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.49878081260359497, test loss: 1.1489930110472106                    \n",
      "100%|██████████| 100/100 [11:23<00:00,  6.84s/trial, best loss: 1.1196094472565272]\n",
      "{'colsample_bytree': 0.6792383875372527, 'gamma': 0.06138772034052431, 'learning_rate': 0.24, 'max_depth': 4.0, 'min_child_weight': 5.0, 'n_estimators': 791.1233820829068, 'reg_alpha': 0.0, 'reg_lambda': 0.012977556303046645}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "df = df.interpolate(method='nearest').ffill().bfill()\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#file_name   =  \"feature_v2.pkl\"\n",
    "#open_file   =  open(file_name, \"rb\")\n",
    "#loaded_list =  pickle.load(open_file)\n",
    "#open_file.close()\n",
    "\n",
    "df_hypopt       = df\n",
    "split_date      = '2021-01-01 00:00:00'\n",
    "df_hypopt_train = df_hypopt.loc[df_hypopt.Datetime < split_date].copy()\n",
    "df_hypopt_test  = df_hypopt.loc[df_hypopt.Datetime >= split_date].copy()\n",
    "\n",
    "y_train         = df_hypopt_train['AIL'].values\n",
    "y_test          = df_hypopt_test['AIL'].values\n",
    "X_train         = df_hypopt_train.drop(['Datetime', 'AIL', 'just_date', 'trend', 'sin.trend',\n",
    "                                        'cos.trend','sin.day', 'cos.day', 'sin.hour', 'cos.hour', \n",
    "                                        'AIL_previous_hour', 'sunlight_avaialbility',\n",
    "                                        'wind_calgary', 'wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
    "                                         'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', \n",
    "                                        'temp_rddr','wind_rddr', 'temp_slvlk', 'wind_slvlk'], axis = 1).values\n",
    "\n",
    "X_test          = df_hypopt_test.drop (['Datetime', 'AIL', 'just_date', 'trend', 'sin.trend',\n",
    "                                         'cos.trend','sin.day', 'cos.day', 'sin.hour', 'cos.hour', \n",
    "                                        'AIL_previous_hour', 'sunlight_avaialbility',\n",
    "                                        'wind_calgary','wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
    "                                         'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', \n",
    "                                        'temp_rddr','wind_rddr', 'temp_slvlk', 'wind_slvlk'], axis = 1).values\n",
    "\n",
    "\n",
    "\n",
    "space={ 'max_depth'        : hp.quniform(\"max_depth\", 2, 5, 1),\n",
    "        'gamma'            : hp.uniform ('gamma', 0,1),\n",
    "        'reg_alpha'        : hp.quniform('reg_alpha', 0,2,1),\n",
    "        'reg_lambda'       : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 7, 1),\n",
    "        'n_estimators'     : hp.uniform('n_estimators', 200, 1300),\n",
    "        #'subsample'        : hp.quniform('subsample', 0.1, 1, 0.01)\n",
    "        'learning_rate'     : hp.quniform('learning_rate', 0.01, 0.3, 0.01)\n",
    "    }\n",
    "\n",
    "\n",
    "#def mape(pred, true):\n",
    "#    return np.abs(np.asarray(pred) - np.asarray(true)) / np.maximum(np.abs(np.assarry(true))\n",
    "\n",
    "delta = 10 #huber-delta\n",
    "\n",
    "def optimize (space):\n",
    "    model=XGBRegressor(\n",
    "                       max_depth        = int(space['max_depth']),\n",
    "                       gamma            = space['gamma'],\n",
    "                       reg_alpha        = int(space['reg_alpha']),\n",
    "                       reg_lambda       = int(space['reg_lambda']),\n",
    "                       colsample_bytree = space['colsample_bytree'],\n",
    "                       min_child_weight = space['min_child_weight'],\n",
    "                       n_estimators     = int(space['n_estimators']), \n",
    "                       learning_rate    = space['learning_rate'],\n",
    "                       random_state = 0)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_loss = np.mean(np.abs((y_train - model.predict(X_train)) / y_train)) * 100\n",
    "    # summarize performance\n",
    "    preds     = model.predict(X_test)\n",
    "    #mae       = mean_absolute_error(y_test, preds)\n",
    "    #loss = np.where(np.abs(y_test - preds) < delta, \n",
    "    #                0.5*((y_test - preds)**2),\n",
    "    #                delta*np.abs(y_test-preds) - 0.5*(delta**2)\n",
    "    #               )\n",
    "    loss = np.mean(np.abs((y_test - preds) / y_test)) * 100\n",
    "    print('train loss: {}, test loss: {}'.format(train_loss, loss))\n",
    "    return loss\n",
    "    \n",
    "trials = Trials()\n",
    "result = fmin(\n",
    "            fn        = optimize,\n",
    "            space     = space,\n",
    "            algo      = tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials    = trials\n",
    ")\n",
    "\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1535582497157681\n"
     ]
    }
   ],
   "source": [
    "#reproducibility check\n",
    "model   = XGBRegressor(colsample_bytree = 0.6792383875372527, \n",
    "                       gamma            = 0.06138772034052431, \n",
    "                       learning_rate    = 0.24,\n",
    "                       max_depth        = 4, \n",
    "                       min_child_weight = 5, \n",
    "                       n_estimators     = 791, \n",
    "                       reg_alpha        = 0, \n",
    "                       reg_lambda       = 0.012977556303,\n",
    "                       random_state = 0)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(np.mean(np.abs((y_test - preds) / y_test)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.938234117363741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_generated_on_15_2_2021_v9_non_holiday_mape_loss_only_temp.joblib.dat']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from joblib import dump\n",
    "\n",
    "column_list = ['hour_of_day',  'day','hour_x_day',  'weekend', 'month', 'year',\n",
    "       'AIL_24h_lagged', 'AIL_2day_lagged',\n",
    "       'AIL_3day_lagged', 'AIL_4day_lagged', 'AIL_5day_lagged',\n",
    "       'AIL_6day_lagged', 'AIL_oneweek_lagged', \n",
    "       'temp_calgary','temp_edmonton', 'temp_calgary_lag1',\n",
    "       'temp_calgary_lag2', 'temp_calgary_lag3', 'temp_calgary_lag1_squared',\n",
    "       'temp_calgary_lag2_squared', 'temp_calgary_lag3_squared',\n",
    "       'temp_calgary_lag1_cube', 'temp_calgary_lag2_cube',\n",
    "       'temp_calgary_lag3_cube', 'temp_edmonton_lag1', 'temp_edmonton_lag2',\n",
    "       'temp_edmonton_lag3', 'temp_edmonton_lag1_squared',\n",
    "       'temp_edmonton_lag2_squared', 'temp_edmonton_lag3_squared',\n",
    "       'temp_edmonton_lag1_cube', 'temp_edmonton_lag2_cube',\n",
    "       'temp_edmonton_lag3_cube', 'hour_temp_calgary', 'month_temp_calgary',\n",
    "       'hour_temp_calgary_lag1', 'hour_temp_calgary_lag2',\n",
    "       'hour_temp_calgary_lag3', 'month_temp_calgary_lag1',\n",
    "       'month_temp_calgary_lag2', 'month_temp_calgary_lag3',\n",
    "       'hour_temp_calgary_lag1_sqd', 'hour_temp_calgary_lag2_sqd',\n",
    "       'hour_temp_calgary_lag3_sqd', 'month_temp_calgary_lag1_cube',\n",
    "       'month_temp_calgary_lag2_cube', 'month_temp_calgary_lag3_cube',\n",
    "       'hour_temp_edmonton', 'month_temp_edmonton', 'hour_temp_edmonton_lag1',\n",
    "       'hour_temp_edmonton_lag2', 'hour_temp_edmonton_lag3',\n",
    "       'month_temp_edmonton_lag1', 'month_temp_edmonton_lag2',\n",
    "       'month_temp_edmonton_lag3', 'hour_temp_edmonton_lag1_sqd',\n",
    "       'hour_temp_edmonton_lag2_sqd', 'hour_temp_edmonton_lag3_sqd',\n",
    "       'month_temp_edmonton_lag1_cube', 'month_temp_edmonton_lag2_cube',\n",
    "       'month_temp_edmonton_lag3_cube' ]\n",
    "\n",
    "df_final = pd.DataFrame(data = df)\n",
    "df_final = df_final.interpolate(method='nearest').ffill().bfill()\n",
    "\n",
    "y_train = pd.DataFrame(df, columns = ['AIL'])\n",
    "y_train = y_train.values\n",
    "X_train = pd.DataFrame(df, columns = column_list)\n",
    "X_train = X_train.values\n",
    "\n",
    "\n",
    "'''\n",
    "{'colsample_bytree': 0.7291500990344976, 'gamma': 0.4938893970952376, \n",
    "'max_depth': 4.0, 'min_child_weight': 6.0, 'n_estimators': 77.15612284031539, \n",
    "'reg_alpha': 1.0, 'reg_lambda': 0.15092719820550313}\n",
    "\n",
    "{'colsample_bytree': 0.8871157197539691, 'gamma': 0.10861672839903519, \n",
    "'max_depth': 2.0, 'min_child_weight': 6.0, 'n_estimators': 779.4072378188877, \n",
    "'reg_alpha': 1.0, 'reg_lambda': 0.4855484354016145}\n",
    "\n",
    "{'colsample_bytree': 0.6872537119887926, 'gamma': 0.2809352456272425,\n",
    "'max_depth': 3.0, 'min_child_weight': 7.0, 'n_estimators': 462.11546701419195,\n",
    "'reg_alpha': 1.0, 'reg_lambda': 0.7694088045714841} --- good\n",
    "\n",
    "{'colsample_bytree': 0.7118179072503236, 'gamma': 0.07719303140261669, \n",
    "'max_depth': 2.0, 'min_child_weight': 4.0, 'n_estimators': 792.4087056123324, \n",
    "'reg_alpha': 2.0, 'reg_lambda': 0.558959862818239}\n",
    "\n",
    "{'colsample_bytree': 0.7043105050508738, 'gamma': 0.3179753015019097, \n",
    "'max_depth': 2.0, 'min_child_weight': 5.0, 'n_estimators': 1088.1650489796807,\n",
    "'reg_alpha': 1.0, 'reg_lambda': 0.2825284742847284}--- good\n",
    "\n",
    "{'colsample_bytree': 0.6792383875372527, 'gamma': 0.06138772034052431, \n",
    "'learning_rate': 0.24, 'max_depth': 4.0, 'min_child_weight': 5.0,\n",
    "'n_estimators': 791.1233820829068, 'reg_alpha': 0.0, 'reg_lambda': 0.012977556303046645}\n",
    "\n",
    "'''\n",
    "model   = XGBRegressor(colsample_bytree = 0.6792383875372527, \n",
    "                       gamma            = 0.06138772034052431, \n",
    "                       learning_rate    = 0.24,\n",
    "                       max_depth        = 4, \n",
    "                       min_child_weight = 5, \n",
    "                       n_estimators     = 792, \n",
    "                       reg_alpha        = 0, \n",
    "                       reg_lambda       = 0.012977556303,\n",
    "                       random_state = 0)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_train)\n",
    "print(np.mean(np.abs((y_train - preds) / y_train)) * 100)\n",
    "\n",
    "#output_columns = ['Datetime','forecast', 'actual'] \n",
    "#output = pd.Dataframe(columns = output_columns)\n",
    "#output['Datetime'] = df['Datetime']\n",
    "#output['forecast'] =\n",
    "\n",
    "\n",
    "# save model to file\n",
    "model_name = 'model_generated_on_{}_{}_{}_v9_non_holiday_mape_loss_only_temp.joblib.dat'.format(datetime.now().day, datetime.now().month, datetime.now().year)\n",
    "joblib.dump(model, filename = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
