{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ret sqlite3\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "\n",
    "class NRGStreamApi:    \n",
    "    \n",
    "    def __init__(self,username=None,password=None):\n",
    "        self.username = 'Fahad'\n",
    "        self.password = 'ABFAHc2'                \n",
    "        self.server = 'api.nrgstream.com'        \n",
    "        self.tokenPath = '/api/security/token'\n",
    "        self.releasePath = '/api/ReleaseToken'\n",
    "        self.tokenPayload = f'grant_type=password&username={self.username}&password={self.password}'\n",
    "        self.tokenExpiry = datetime.now() - timedelta(seconds=60)\n",
    "        self.accessToken = \"\"        \n",
    "        \n",
    "    def getToken(self):\n",
    "        try:\n",
    "            if self.isTokenValid() == False:                             \n",
    "                headers = { }        \n",
    "                # Connect to API server to get a token\n",
    "                conn = http.client.HTTPSConnection(self.server)\n",
    "                conn.request('POST', self.tokenPath, self.tokenPayload, headers)\n",
    "                res = conn.getresponse()                \n",
    "                res_code = res.code\n",
    "                # Check if the response is good\n",
    "                \n",
    "                if res_code == 200:\n",
    "                    res_data = res.read()\n",
    "                    # Decode the token into an object\n",
    "                    jsonData = json.loads(res_data.decode('utf-8'))\n",
    "                    self.accessToken = jsonData['access_token']                         \n",
    "                    # Calculate new expiry date\n",
    "                    self.tokenExpiry = datetime.now() + timedelta(seconds=jsonData['expires_in'])                        \n",
    "                    #print('token obtained')\n",
    "                    #print(self.accessToken)\n",
    "                else:\n",
    "                    res_data = res.read()\n",
    "                    print(res_data.decode('utf-8'))\n",
    "                conn.close()                          \n",
    "        except Exception as e:\n",
    "            print(\"getToken: \" + str(e))\n",
    "            # Release token if an error occured\n",
    "            self.releaseToken()      \n",
    "\n",
    "    def releaseToken(self):\n",
    "        try:            \n",
    "            headers = {}\n",
    "            headers['Authorization'] = f'Bearer {self.accessToken}'            \n",
    "            conn = http.client.HTTPSConnection(self.server)\n",
    "            conn.request('DELETE', self.releasePath, None, headers)  \n",
    "            res = conn.getresponse()\n",
    "            res_code = res.code\n",
    "            if res_code == 200:   \n",
    "                # Set expiration date back to guarantee isTokenValid() returns false                \n",
    "                self.tokenExpiry = datetime.now() - timedelta(seconds=60)\n",
    "                #print('token released')            \n",
    "        except Exception as e:\n",
    "            print(\"releaseToken: \" + str(e))\n",
    "                    \n",
    "    def isTokenValid(self):\n",
    "        if self.tokenExpiry==None:\n",
    "            return False\n",
    "        elif datetime.now() >= self.tokenExpiry:            \n",
    "            return False\n",
    "        else:\n",
    "            return True            \n",
    "    \n",
    "    def GetStreamDataByStreamId(self,streamIds, fromDate, toDate, dataFormat='csv', dataOption=''):\n",
    "        stream_data = \"\" \n",
    "        # Set file format to csv or json            \n",
    "        DataFormats = {}\n",
    "        DataFormats['csv'] = 'text/csv'\n",
    "        DataFormats['json'] = 'Application/json'\n",
    "        \n",
    "        try:                            \n",
    "            for streamId in streamIds:            \n",
    "                # Get an access token            \n",
    "                self.getToken()    \n",
    "                if self.isTokenValid():\n",
    "                    # Setup the path for data request. Pass dates in via function call\n",
    "                    path = f'/api/StreamData/{streamId}'\n",
    "                    if fromDate != '' and toDate != '':\n",
    "                        path += f'?fromDate={fromDate.replace(\" \", \"%20\")}&toDate={toDate.replace(\" \", \"%20\")}'\n",
    "                    if dataOption != '':\n",
    "                        if fromDate != '' and toDate != '':\n",
    "                            path += f'&dataOption={dataOption}'        \n",
    "                        else:\n",
    "                            path += f'?dataOption={dataOption}'        \n",
    "                    \n",
    "                    # Create request header\n",
    "                    headers = {}            \n",
    "                    headers['Accept'] = DataFormats[dataFormat]\n",
    "                    headers['Authorization']= f'Bearer {self.accessToken}'\n",
    "                    \n",
    "                    # Connect to API server\n",
    "                    conn = http.client.HTTPSConnection(self.server)\n",
    "                    conn.request('GET', path, None, headers)\n",
    "                    res = conn.getresponse()        \n",
    "                    res_code = res.code                    \n",
    "                    if res_code == 200:   \n",
    "                        try:\n",
    "                            print(f'{datetime.now()} Outputing stream {path} res code {res_code}')\n",
    "                            # output return data to a text file            \n",
    "                            if dataFormat == 'csv':\n",
    "                                stream_data += res.read().decode('utf-8').replace('\\r\\n','\\n') \n",
    "                            elif dataFormat == 'json':\n",
    "                                stream_data += json.dumps(json.loads(res.read().decode('utf-8')), indent=2, sort_keys=False)\n",
    "                            conn.close()\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(str(e))            \n",
    "                            self.releaseToken()\n",
    "                            return None  \n",
    "                    else:\n",
    "                        print(str(res_code) + \" - \" + str(res.reason) + \" - \" + str(res.read().decode('utf-8')))\n",
    "                    \n",
    "                self.releaseToken()   \n",
    "                # Wait 1 second before next request\n",
    "                time.sleep(1)\n",
    "            return stream_data        \n",
    "        except Exception as e:\n",
    "            print(str(e))    \n",
    "            self.releaseToken()\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    def StreamDataOptions(self, streamId, dataFormat='csv'):\n",
    "        try:      \n",
    "            DataFormats = {}\n",
    "            DataFormats['csv'] = 'text/csv'\n",
    "            DataFormats['json'] = 'Application/json'\n",
    "            resultSet = {}\n",
    "            for streamId in streamIds:\n",
    "                # Get an access token    \n",
    "                if streamId not in resultSet:\n",
    "                    self.getToken()                        \n",
    "                    if self.isTokenValid():                 \n",
    "                        # Setup the path for data request.\n",
    "                        path = f'/api/StreamDataOptions/{streamId}'                        \n",
    "                        # Create request header\n",
    "                        headers = {}     \n",
    "                        headers['Accept'] = DataFormats[dataFormat]                                   \n",
    "                        headers['Authorization'] = f'Bearer {self.accessToken}'\n",
    "                        # Connect to API server\n",
    "                        conn = http.client.HTTPSConnection(self.server)\n",
    "                        conn.request('GET', path, None, headers)\n",
    "                        res = conn.getresponse()\n",
    "                        self.releaseToken()       \n",
    "                        if dataFormat == 'csv':\n",
    "                            resultSet[streamId] = res.read().decode('utf-8').replace('\\r\\n','\\n') \n",
    "                        elif dataFormat == 'json':\n",
    "                            resultSet[streamId] = json.dumps(json.loads(res.read().decode('utf-8')), indent=2, sort_keys=False)                            \n",
    "                    time.sleep(1)                        \n",
    "            return resultSet            \n",
    "        except Exception as e:\n",
    "            print(str(e))    \n",
    "            self.releaseToken()\n",
    "            return None          \n",
    "        \n",
    "        except Exception as e:            \n",
    "            self.releaseToken()                        \n",
    "            return str(e)\n",
    "\n",
    "        \n",
    "# Authenticate with your NRG Stream username and password    \n",
    "nrgStreamApi = NRGStreamApi('Username','Password')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqlite3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e1460d309235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# view columns in table (or whatever you want to call with SQL syntax)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT * FROM HISTORICALFCAST\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e1460d309235>\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weather_db.db'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# view columns in table (or whatever you want to call with SQL syntax)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sqlite3' is not defined"
     ]
    }
   ],
   "source": [
    "def run_query(q):\n",
    "    with sqlite3.connect('weather_db.db') as conn:\n",
    "        return pd.read_sql_query(q, conn)\n",
    "\n",
    "# view columns in table (or whatever you want to call with SQL syntax)\n",
    "query = \"SELECT * FROM HISTORICALFCAST\"\n",
    "df = run_query(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_end_year  = pd.to_datetime(df.iloc[df.shape[0]-1,0]).year\n",
    "db_end_month = pd.to_datetime(df.iloc[df.shape[0]-1,0]).month\n",
    "db_end_date =  pd.to_datetime(df.iloc[df.shape[0]-1,0]).day\n",
    "print(db_end_year,db_end_month,db_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromDate = '{}/{}/{}'.format(db_end_month,db_end_date+1,db_end_year)\n",
    "\n",
    "now_time = datetime.now()\n",
    "year_of_run = now_time.year\n",
    "month_of_run = now_time.month\n",
    "day_of_run  = now_time.day\n",
    "\n",
    "\n",
    "toDate = '{}/{}/{}'.format(month_of_run, day_of_run+1,year_of_run)\n",
    "\n",
    "print(fromDate, toDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clgry   = pd.DataFrame()\n",
    "df_edmtn   = pd.DataFrame()\n",
    "df_ftmcmry = pd.DataFrame()\n",
    "df_lthbrg  = pd.DataFrame()\n",
    "df_mdcnht  = pd.DataFrame()\n",
    "df_rddr    = pd.DataFrame()\n",
    "df_slvlk   = pd.DataFrame()\n",
    "df_list = {}\n",
    "\n",
    "streams = [242498, 242497, 242500, 242508, 242511, 242519, 242522]\n",
    "city_names = ['calgary', 'edmonton', 'ftmcmry','lthbrg','mdcnht', 'rddr','slvlk']\n",
    "k = 0\n",
    "\n",
    "for i in streams:\n",
    "    stream_data = nrgStreamApi.GetStreamDataByStreamId([i], fromDate, toDate, 'csv', '')        \n",
    "    STREAM_DATA = StringIO(stream_data)\n",
    "    df = pd.read_csv(STREAM_DATA, sep=\";\")\n",
    "    length = df.shape[0]\n",
    "    df = df[16:length] # removing header information\n",
    "    df.columns = [\"Datetime,temp,wind,direction\"]\n",
    "    new = df['Datetime,temp,wind,direction'].str.split(\",\", n = 4, expand = True) \n",
    "    # making separate first name column from new data frame \n",
    "    df[\"Datetime\"]= new[0] \n",
    "    df[\"temp\"]= new[1] \n",
    "    df[\"wind\"] = new [2]\n",
    "    df[\"direction\"] = new[3]\n",
    "    df = df.drop(['Datetime,temp,wind,direction','direction'],axis=1)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.columns = [str(col) + '_'+ city_names[k] for col in df.columns]\n",
    "    df_list[k] = df\n",
    "    k = k+1\n",
    "\n",
    "df_clgry   = df_list[0]\n",
    "df_edmtn   = df_list[1]\n",
    "df_ftmcmry = df_list[2]\n",
    "df_lthbrg  = df_list[3]\n",
    "df_mdcnht  = df_list[4]\n",
    "df_rddr    = df_list[5]\n",
    "df_slvlk   = df_list[6]\n",
    "\n",
    "\n",
    "alberta_weather_merged = pd.concat([df_clgry, df_edmtn, df_ftmcmry, \n",
    "                                   df_lthbrg, df_mdcnht,\n",
    "                                   df_rddr, df_slvlk], axis=1)\n",
    "\n",
    "alberta_weather_merged = alberta_weather_merged[['Datetime_calgary', 'temp_calgary', 'wind_calgary',\n",
    "       'temp_edmonton', 'wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
    "       'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', 'temp_rddr',\n",
    "       'wind_rddr', 'temp_slvlk', 'wind_slvlk']]\n",
    "alberta_weather_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_weather_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('weather_db.db')\n",
    "c = conn.cursor()\n",
    "c.executemany(\n",
    "    '''\n",
    "    INSERT INTO HISTORICALFCAST(Datetime_calgary, temp_calgary, wind_calgary, temp_edmonton,\n",
    "    wind_edmonton, temp_ftmcmry, wind_ftmcmry, temp_lthbrg,\n",
    "    wind_lthbrg, temp_mdcnht, wind_mdcnht, temp_rddr, wind_rddr,\n",
    "    temp_slvlk, wind_slvlk) VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "    ''', alberta_weather_merged.values)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(q):\n",
    "    with sqlite3.connect('weather_db.db') as conn:\n",
    "        return pd.read_sql_query(q, conn)\n",
    "\n",
    "# view columns in table (or whatever you want to call with SQL syntax)\n",
    "query = \"SELECT * FROM HISTORICALFCAST\"\n",
    "df = run_query(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
