{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lN-RLyXqCQrf",
    "outputId": "251a4996-9c6c-4474-f362-83545da1d404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-12 22:29:49.957202 Outputing stream /api/StreamData/3?fromDate=01/01/2018&toDate=02/11/2021 res code 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>10221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>10082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>9949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>9886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>9930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27283</th>\n",
       "      <td>2021-02-10 19:00:00</td>\n",
       "      <td>11485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27284</th>\n",
       "      <td>2021-02-10 20:00:00</td>\n",
       "      <td>11364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>2021-02-10 21:00:00</td>\n",
       "      <td>11195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27286</th>\n",
       "      <td>2021-02-10 22:00:00</td>\n",
       "      <td>10961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27287</th>\n",
       "      <td>2021-02-10 23:00:00</td>\n",
       "      <td>10839.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27288 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime      AIL\n",
       "0     2018-01-01 00:00:00  10221.0\n",
       "1     2018-01-01 01:00:00  10082.0\n",
       "2     2018-01-01 02:00:00   9949.0\n",
       "3     2018-01-01 03:00:00   9886.0\n",
       "4     2018-01-01 04:00:00   9930.0\n",
       "...                   ...      ...\n",
       "27283 2021-02-10 19:00:00  11485.0\n",
       "27284 2021-02-10 20:00:00  11364.0\n",
       "27285 2021-02-10 21:00:00  11195.0\n",
       "27286 2021-02-10 22:00:00  10961.0\n",
       "27287 2021-02-10 23:00:00  10839.0\n",
       "\n",
       "[27288 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import http.client\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "\n",
    "class NRGStreamApi:    \n",
    "    \n",
    "    def __init__(self,username=None,password=None):\n",
    "        self.username = 'Fahad'\n",
    "        self.password = 'ABFAHc2'                \n",
    "        self.server = 'api.nrgstream.com'        \n",
    "        self.tokenPath = '/api/security/token'\n",
    "        self.releasePath = '/api/ReleaseToken'\n",
    "        self.tokenPayload = f'grant_type=password&username={self.username}&password={self.password}'\n",
    "        self.tokenExpiry = datetime.now() - timedelta(seconds=60)\n",
    "        self.accessToken = \"\"        \n",
    "        \n",
    "    def getToken(self):\n",
    "        try:\n",
    "            if self.isTokenValid() == False:                             \n",
    "                headers = { }        \n",
    "                # Connect to API server to get a token\n",
    "                conn = http.client.HTTPSConnection(self.server)\n",
    "                conn.request('POST', self.tokenPath, self.tokenPayload, headers)\n",
    "                res = conn.getresponse()                \n",
    "                res_code = res.code\n",
    "                # Check if the response is good\n",
    "                \n",
    "                if res_code == 200:\n",
    "                    res_data = res.read()\n",
    "                    # Decode the token into an object\n",
    "                    jsonData = json.loads(res_data.decode('utf-8'))\n",
    "                    self.accessToken = jsonData['access_token']                         \n",
    "                    # Calculate new expiry date\n",
    "                    self.tokenExpiry = datetime.now() + timedelta(seconds=jsonData['expires_in'])                        \n",
    "                    #print('token obtained')\n",
    "                    #print(self.accessToken)\n",
    "                else:\n",
    "                    res_data = res.read()\n",
    "                    print(res_data.decode('utf-8'))\n",
    "                conn.close()                          \n",
    "        except Exception as e:\n",
    "            print(\"getToken: \" + str(e))\n",
    "            # Release token if an error occured\n",
    "            self.releaseToken()      \n",
    "\n",
    "    def releaseToken(self):\n",
    "        try:            \n",
    "            headers = {}\n",
    "            headers['Authorization'] = f'Bearer {self.accessToken}'            \n",
    "            conn = http.client.HTTPSConnection(self.server)\n",
    "            conn.request('DELETE', self.releasePath, None, headers)  \n",
    "            res = conn.getresponse()\n",
    "            res_code = res.code\n",
    "            if res_code == 200:   \n",
    "                # Set expiration date back to guarantee isTokenValid() returns false                \n",
    "                self.tokenExpiry = datetime.now() - timedelta(seconds=60)\n",
    "                #print('token released')            \n",
    "        except Exception as e:\n",
    "            print(\"releaseToken: \" + str(e))\n",
    "                    \n",
    "    def isTokenValid(self):\n",
    "        if self.tokenExpiry==None:\n",
    "            return False\n",
    "        elif datetime.now() >= self.tokenExpiry:            \n",
    "            return False\n",
    "        else:\n",
    "            return True            \n",
    "    \n",
    "    def GetStreamDataByStreamId(self,streamIds, fromDate, toDate, dataFormat='csv', dataOption=''):\n",
    "        stream_data = \"\" \n",
    "        # Set file format to csv or json            \n",
    "        DataFormats = {}\n",
    "        DataFormats['csv'] = 'text/csv'\n",
    "        DataFormats['json'] = 'Application/json'\n",
    "        \n",
    "        try:                            \n",
    "            for streamId in streamIds:            \n",
    "                # Get an access token            \n",
    "                self.getToken()    \n",
    "                if self.isTokenValid():\n",
    "                    # Setup the path for data request. Pass dates in via function call\n",
    "                    path = f'/api/StreamData/{streamId}'\n",
    "                    if fromDate != '' and toDate != '':\n",
    "                        path += f'?fromDate={fromDate.replace(\" \", \"%20\")}&toDate={toDate.replace(\" \", \"%20\")}'\n",
    "                    if dataOption != '':\n",
    "                        if fromDate != '' and toDate != '':\n",
    "                            path += f'&dataOption={dataOption}'        \n",
    "                        else:\n",
    "                            path += f'?dataOption={dataOption}'        \n",
    "                    \n",
    "                    # Create request header\n",
    "                    headers = {}            \n",
    "                    headers['Accept'] = DataFormats[dataFormat]\n",
    "                    headers['Authorization']= f'Bearer {self.accessToken}'\n",
    "                    \n",
    "                    # Connect to API server\n",
    "                    conn = http.client.HTTPSConnection(self.server)\n",
    "                    conn.request('GET', path, None, headers)\n",
    "                    res = conn.getresponse()        \n",
    "                    res_code = res.code                    \n",
    "                    if res_code == 200:   \n",
    "                        try:\n",
    "                            print(f'{datetime.now()} Outputing stream {path} res code {res_code}')\n",
    "                            # output return data to a text file            \n",
    "                            if dataFormat == 'csv':\n",
    "                                stream_data += res.read().decode('utf-8').replace('\\r\\n','\\n') \n",
    "                            elif dataFormat == 'json':\n",
    "                                stream_data += json.dumps(json.loads(res.read().decode('utf-8')), indent=2, sort_keys=False)\n",
    "                            conn.close()\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(str(e))            \n",
    "                            self.releaseToken()\n",
    "                            return None  \n",
    "                    else:\n",
    "                        print(str(res_code) + \" - \" + str(res.reason) + \" - \" + str(res.read().decode('utf-8')))\n",
    "                    \n",
    "                self.releaseToken()   \n",
    "                # Wait 1 second before next request\n",
    "                time.sleep(1)\n",
    "            return stream_data        \n",
    "        except Exception as e:\n",
    "            print(str(e))    \n",
    "            self.releaseToken()\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    def StreamDataOptions(self, streamId, dataFormat='csv'):\n",
    "        try:      \n",
    "            DataFormats = {}\n",
    "            DataFormats['csv'] = 'text/csv'\n",
    "            DataFormats['json'] = 'Application/json'\n",
    "            resultSet = {}\n",
    "            for streamId in streamIds:\n",
    "                # Get an access token    \n",
    "                if streamId not in resultSet:\n",
    "                    self.getToken()                        \n",
    "                    if self.isTokenValid():                 \n",
    "                        # Setup the path for data request.\n",
    "                        path = f'/api/StreamDataOptions/{streamId}'                        \n",
    "                        # Create request header\n",
    "                        headers = {}     \n",
    "                        headers['Accept'] = DataFormats[dataFormat]                                   \n",
    "                        headers['Authorization'] = f'Bearer {self.accessToken}'\n",
    "                        # Connect to API server\n",
    "                        conn = http.client.HTTPSConnection(self.server)\n",
    "                        conn.request('GET', path, None, headers)\n",
    "                        res = conn.getresponse()\n",
    "                        self.releaseToken()       \n",
    "                        if dataFormat == 'csv':\n",
    "                            resultSet[streamId] = res.read().decode('utf-8').replace('\\r\\n','\\n') \n",
    "                        elif dataFormat == 'json':\n",
    "                            resultSet[streamId] = json.dumps(json.loads(res.read().decode('utf-8')), indent=2, sort_keys=False)                            \n",
    "                    time.sleep(1)                        \n",
    "            return resultSet            \n",
    "        except Exception as e:\n",
    "            print(str(e))    \n",
    "            self.releaseToken()\n",
    "            return None          \n",
    "        \n",
    "        except Exception as e:            \n",
    "            self.releaseToken()                        \n",
    "            return str(e)\n",
    "\n",
    "        \n",
    "# Authenticate with your NRG Stream username and password    \n",
    "nrgStreamApi = NRGStreamApi('Username','Password')         \n",
    "# Date range for your data request\n",
    "# Date format must be mm/dd/yyyy\n",
    "fromDate = '01/01/2018'\n",
    "toDate =   '02/11/2021'\n",
    "# Specify output format - 'csv' or 'json'\n",
    "dataFormat = 'csv'\n",
    "# Data Option\n",
    "dataOption = ''\n",
    "stream = [3]\n",
    "for i in stream:\n",
    "    nrgStreamApi = NRGStreamApi('Username','Password')\n",
    "    ids= [i]\n",
    "    stream_data = nrgStreamApi.GetStreamDataByStreamId(ids, fromDate, toDate, dataFormat, dataOption)        \n",
    "    STREAM_DATA = StringIO(stream_data)\n",
    "    df = pd.read_csv(STREAM_DATA, sep=\";\")\n",
    "\n",
    "    \n",
    "df = df[14:df.shape[0]]\n",
    "df.columns = [\"Datetime,AIL\"]\n",
    "new = df['Datetime,AIL'].str.split(\",\", n = 2, expand = True) \n",
    "# making separate first name column from new data frame \n",
    "df[\"Datetime\"]= new[0] \n",
    "# making separate last name column from new data frame \n",
    "df[\"AIL\"]= new[1] \n",
    "df['AIL'] = pd.to_numeric(df['AIL'],errors='coerce')\n",
    "df['Datetime']= pd.to_datetime(df['Datetime'])\n",
    "df= df.drop(columns=['Datetime,AIL'],axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "J_09JQKOCQrj",
    "outputId": "548db622-7155-4b2f-96e2-680bbdbac81c"
   },
   "outputs": [],
   "source": [
    "df['hour_of_day']= df['Datetime'].dt.hour\n",
    "\n",
    "#------------------------------\n",
    "import numpy as np\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df['hour_of_day'] < 7),\n",
    "    (df['hour_of_day'] >= 7) & (df['hour_of_day'] <= 19),\n",
    "    (df['hour_of_day'] > 19)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [1, 0, 1]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['off_peak'] = np.select(conditions, values)\n",
    "\n",
    "conditions = [\n",
    "    (df['hour_of_day'] < 7),\n",
    "    (df['hour_of_day'] >= 7) & (df['hour_of_day'] <= 19),\n",
    "    (df['hour_of_day'] > 19)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [0, 1, 0]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['on_peak'] = np.select(conditions, values)\n",
    "\n",
    "#----------------------\n",
    "df['just_date'] = df['Datetime'].dt.date\n",
    "dates = df['just_date']\n",
    "day = pd.Series([d.timetuple().tm_yday for d in dates])\n",
    "df['day'] = day\n",
    "\n",
    "#------------------------\n",
    "\n",
    "df['sin.day'] = np.sin(day*2*np.pi/365 + np.pi/4)\n",
    "df['cos.day'] = np.cos(day*2*np.pi/365 + np.pi/4)\n",
    "df['sin.hour'] = np.sin(df['hour_of_day']*2*np.pi/24)\n",
    "df['cos.hour'] = np.cos(df['hour_of_day']*2*np.pi/24)\n",
    "#-------------------------\n",
    "\n",
    "weekdays = [d.weekday() for d in dates]\n",
    "df['weekend'] = [1 if d >= 5 else 0 for d in weekdays]\n",
    "for i, s in enumerate(['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday',\n",
    "            'sunday']):\n",
    "    df[s] = [1 if d == i else 0 for d in weekdays]\n",
    "\n",
    "#-----------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "month = [[d.timetuple().tm_mon-1] for d in dates]\n",
    "month_bin = OneHotEncoder(dtype=int, sparse=False).fit_transform(month)\n",
    "for i in range(12):\n",
    "    df['month_%d' % i] = month_bin[:, i]\n",
    "    \n",
    "for i in range(24):\n",
    "    df['hour_%d' % i] = np.where(df['hour_of_day']==i, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AIL</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>off_peak</th>\n",
       "      <th>on_peak</th>\n",
       "      <th>just_date</th>\n",
       "      <th>day</th>\n",
       "      <th>sin.day</th>\n",
       "      <th>cos.day</th>\n",
       "      <th>sin.hour</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>year</th>\n",
       "      <th>sunlight_avaialbility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27283</th>\n",
       "      <td>2021-02-10 19:00:00</td>\n",
       "      <td>11485.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27284</th>\n",
       "      <td>2021-02-10 20:00:00</td>\n",
       "      <td>11364.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>2021-02-10 21:00:00</td>\n",
       "      <td>11195.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27286</th>\n",
       "      <td>2021-02-10 22:00:00</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27287</th>\n",
       "      <td>2021-02-10 23:00:00</td>\n",
       "      <td>10839.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27288 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime      AIL  hour_of_day  off_peak  on_peak  \\\n",
       "0     2018-01-01 00:00:00  10221.0            0         1        0   \n",
       "1     2018-01-01 01:00:00  10082.0            1         1        0   \n",
       "2     2018-01-01 02:00:00   9949.0            2         1        0   \n",
       "3     2018-01-01 03:00:00   9886.0            3         1        0   \n",
       "4     2018-01-01 04:00:00   9930.0            4         1        0   \n",
       "...                   ...      ...          ...       ...      ...   \n",
       "27283 2021-02-10 19:00:00  11485.0           19         0        1   \n",
       "27284 2021-02-10 20:00:00  11364.0           20         1        0   \n",
       "27285 2021-02-10 21:00:00  11195.0           21         1        0   \n",
       "27286 2021-02-10 22:00:00  10961.0           22         1        0   \n",
       "27287 2021-02-10 23:00:00  10839.0           23         1        0   \n",
       "\n",
       "        just_date  day   sin.day   cos.day  sin.hour  ...  hour_16  hour_17  \\\n",
       "0      2018-01-01    1  0.719174  0.694830  0.000000  ...        0        0   \n",
       "1      2018-01-01    1  0.719174  0.694830  0.258819  ...        0        0   \n",
       "2      2018-01-01    1  0.719174  0.694830  0.500000  ...        0        0   \n",
       "3      2018-01-01    1  0.719174  0.694830  0.707107  ...        0        0   \n",
       "4      2018-01-01    1  0.719174  0.694830  0.866025  ...        0        0   \n",
       "...           ...  ...       ...       ...       ...  ...      ...      ...   \n",
       "27283  2021-02-10   41  0.996832  0.079532 -0.965926  ...        0        0   \n",
       "27284  2021-02-10   41  0.996832  0.079532 -0.866025  ...        0        0   \n",
       "27285  2021-02-10   41  0.996832  0.079532 -0.707107  ...        0        0   \n",
       "27286  2021-02-10   41  0.996832  0.079532 -0.500000  ...        0        0   \n",
       "27287  2021-02-10   41  0.996832  0.079532 -0.258819  ...        0        0   \n",
       "\n",
       "       hour_18  hour_19  hour_20  hour_21  hour_22  hour_23  year  \\\n",
       "0            0        0        0        0        0        0  2018   \n",
       "1            0        0        0        0        0        0  2018   \n",
       "2            0        0        0        0        0        0  2018   \n",
       "3            0        0        0        0        0        0  2018   \n",
       "4            0        0        0        0        0        0  2018   \n",
       "...        ...      ...      ...      ...      ...      ...   ...   \n",
       "27283        0        1        0        0        0        0  2021   \n",
       "27284        0        0        1        0        0        0  2021   \n",
       "27285        0        0        0        1        0        0  2021   \n",
       "27286        0        0        0        0        1        0  2021   \n",
       "27287        0        0        0        0        0        1  2021   \n",
       "\n",
       "       sunlight_avaialbility  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "27283                      0  \n",
       "27284                      0  \n",
       "27285                      0  \n",
       "27286                      0  \n",
       "27287                      0  \n",
       "\n",
       "[27288 rows x 57 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls = pd.ExcelFile('edmonton_sunrise_sunset.xls')\n",
    "dfess_2015 = pd.read_excel(xls, '2015') #df= dafaframe, e= edmonston, ss= sunrise and sunset \n",
    "dfess_2016 = pd.read_excel(xls, '2016')\n",
    "\n",
    "df['year']= df['Datetime'].dt.year\n",
    "dfess_2015 = dfess_2015[['Sunrise_hr', 'Sunset_hr']]\n",
    "dfess_2016 = dfess_2016[['Sunrise_hr', 'Sunset_hr']]\n",
    "df['sunlight_avaialbility'] =  0\n",
    "\n",
    "for i in range(0,df.shape[0]):\n",
    "    if (df.iloc[i,df.columns.get_loc('year')]%4 ==0 and df.iloc[i,df.columns.get_loc('year')]%100 !=0):\n",
    "        criteria = df.iloc[i,df.columns.get_loc('day')] #day_of_year\n",
    "        sunrise  = dfess_2016.iloc[criteria-1,0] #sunrise\n",
    "        sunset   = dfess_2016.iloc[criteria-1,1] #sunset\n",
    "        if (df.iloc[i,df.columns.get_loc('hour_of_day')]>= sunrise) and (df.iloc[i,df.columns.get_loc('hour_of_day')] <= sunset):\n",
    "            df.iloc[i,df.columns.get_loc('sunlight_avaialbility')] = 1\n",
    "    else:\n",
    "        criteria = df.iloc[i,df.columns.get_loc('day')] #day_of_year\n",
    "        sunrise  = dfess_2015.iloc[criteria-1,0]#sunrise\n",
    "        sunset   = dfess_2015.iloc[criteria-1,1] #sunset\n",
    "        if (df.iloc[i,df.columns.get_loc('hour_of_day')]>= sunrise) and (df.iloc[i,df.columns.get_loc('hour_of_day')] <= sunset):\n",
    "            df.iloc[i,df.columns.get_loc('sunlight_avaialbility')] = 1\n",
    "            \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BHBZE743CQrn",
    "outputId": "1b16709f-1858-4602-bc4d-400f40ba1828"
   },
   "outputs": [],
   "source": [
    "df['AIL_previous_hour']  = df['AIL'].shift(1)     # col_index = 57\n",
    "df['AIL_24h_lagged']     = df['AIL'].shift(24)    # col_index = 58\n",
    "df['AIL_2day_lagged']    = df['AIL'].shift(24*2)  # col_index = 59\n",
    "df['AIL_3day_lagged']    = df['AIL'].shift(24*3)  # col_index = 60\n",
    "df['AIL_4day_lagged']    = df['AIL'].shift(24*4)  # col_index = 61\n",
    "df['AIL_5day_lagged']    = df['AIL'].shift(24*5)  # col_index = 62\n",
    "df['AIL_6day_lagged']    = df['AIL'].shift(24*6)  # col_index = 63\n",
    "df['AIL_oneweek_lagged'] = df['AIL'].shift(24*7)  #col_index = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-12 22:49:03.240190 Outputing stream /api/StreamData/3?fromDate=12/31/2017&toDate=12/31/2017 res code 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        10571.0\n",
       "1        10221.0\n",
       "2        10082.0\n",
       "3         9949.0\n",
       "4         9886.0\n",
       "          ...   \n",
       "27283    11665.0\n",
       "27284    11485.0\n",
       "27285    11364.0\n",
       "27286    11195.0\n",
       "27287    10961.0\n",
       "Name: AIL_previous_hour, Length: 27288, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authenticate with your NRG Stream username and password    \n",
    "nrgStreamApi = NRGStreamApi('Username','Password')         \n",
    "# Date range for your data request\n",
    "# Date format must be mm/dd/yyyy\n",
    "fromDate = '12/31/2017'\n",
    "toDate =   '12/31/2017'\n",
    "# Specify output format - 'csv' or 'json'\n",
    "dataFormat = 'csv'\n",
    "# Data Option\n",
    "dataOption = ''\n",
    "stream = [3]\n",
    "for i in stream:\n",
    "    nrgStreamApi = NRGStreamApi('Username','Password')\n",
    "    ids= [i]\n",
    "    stream_data = nrgStreamApi.GetStreamDataByStreamId(ids, fromDate, toDate, dataFormat, dataOption)        \n",
    "    STREAM_DATA = StringIO(stream_data)\n",
    "    test_df = pd.read_csv(STREAM_DATA, sep=\";\")\n",
    "\n",
    "    \n",
    "test_df = test_df[14:test_df.shape[0]]\n",
    "test_df.columns = [\"Datetime,AIL\"]\n",
    "new = test_df['Datetime,AIL'].str.split(\",\", n = 2, expand = True) \n",
    "# making separate first name column from new data frame \n",
    "test_df[\"Datetime\"]= new[0] \n",
    "# making separate last name column from new data frame \n",
    "test_df[\"AIL\"]= new[1] \n",
    "test_df['AIL'] = pd.to_numeric(df['AIL'],errors='coerce')\n",
    "test_df['Datetime']= pd.to_datetime(df['Datetime'])\n",
    "test_df= test_df.drop(columns=['Datetime,AIL'],axis=1)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "df.iloc[0,df.columns.get_loc('AIL_previous_hour')] = test_df.iloc[23,1]\n",
    "\n",
    "df.iloc[:,df.columns.get_loc('AIL_previous_hour')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-12 23:17:06.799793 Outputing stream /api/StreamData/3?fromDate=01/01/2018&toDate=01/08/2018 res code 200\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with your NRG Stream username and password    \n",
    "nrgStreamApi = NRGStreamApi('Username','Password')         \n",
    "# Date range for your data request\n",
    "# Date format must be mm/dd/yyyy\n",
    "fromDate = '01/01/2018'\n",
    "toDate =   '01/08/2018'\n",
    "# Specify output format - 'csv' or 'json'\n",
    "dataFormat = 'csv'\n",
    "# Data Option\n",
    "dataOption = ''\n",
    "stream = [3]\n",
    "for i in stream:\n",
    "    nrgStreamApi = NRGStreamApi('Username','Password')\n",
    "    ids= [i]\n",
    "    stream_data = nrgStreamApi.GetStreamDataByStreamId(ids, fromDate, toDate, dataFormat, dataOption)        \n",
    "    STREAM_DATA = StringIO(stream_data)\n",
    "    test_df = pd.read_csv(STREAM_DATA, sep=\";\")\n",
    "    #test_df = test_df.iloc[1:14+7*24+1]\n",
    "    #test_df = test_df[0: 183]\n",
    "    test_df.columns = [\"Datetime,AIL\"]\n",
    "    new = test_df['Datetime,AIL'].str.split(\",\", n = 2, expand = True) \n",
    "    # making separate first name column from new data frame \n",
    "    test_df[\"Datetime\"]= new[0] \n",
    "    # making separate last name column from new data frame \n",
    "    test_df[\"AIL\"]= new[1] \n",
    "    test_df['AIL'] = pd.to_numeric(df['AIL'],errors='coerce')\n",
    "    test_df['Datetime']= pd.to_datetime(df['Datetime'])\n",
    "    test_df= test_df.drop(columns=['Datetime,AIL'],axis=1)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "#test_df\n",
    "df.iloc[0:7*24, df.columns.get_loc('AIL_oneweek_lagged')] = test_df.iloc[0:24*7,1]\n",
    "df.iloc[0:6*24, df.columns.get_loc('AIL_6day_lagged')]    = test_df.iloc[0:24*6,1]\n",
    "df.iloc[0:5*24, df.columns.get_loc('AIL_5day_lagged')]    = test_df.iloc[0:24*5,1]\n",
    "df.iloc[0:4*24, df.columns.get_loc('AIL_4day_lagged')]    = test_df.iloc[0:24*4,1]\n",
    "df.iloc[0:3*24, df.columns.get_loc('AIL_3day_lagged')]    = test_df.iloc[0:24*3,1]\n",
    "df.iloc[0:2*24, df.columns.get_loc('AIL_2day_lagged')]    = test_df.iloc[0:24*2,1]\n",
    "df.iloc[0:1*24, df.columns.get_loc('AIL_24h_lagged')]     = test_df.iloc[0:24*1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "BnPMggcSCQro",
    "outputId": "fcb3dc19-0a4a-493a-fdfc-82661ddc9d06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport holidays\\nhl_list       = holidays.CA(years=[2018,2019,2020,2021], prov = 'AB').items()\\ndf_hl         = pd.DataFrame(hl_list)\\ndf_hl.columns = ['date','title']\\ndf_hl['date'] = pd.to_datetime(df_hl['date'])\\n#df_hl         = df_hl.sort_values('date')\\ndf_hl['date'] = df_hl['date'].dt.date\\ndf_hl\\n\\n#df['holiday'] = 0\\n#pd.to_datetime(df.iloc[i,df.columns.get_loc('just_date')]) == df_hl[j, df_hl.columns.get_loc('date')]\\n\\n#for i in range(0, df.shape[0]):\\n#    for j in range(0,df_hl.shape[0]):\\n#        if pd.to_datetime(df.iloc[i,df.columns.get_loc('just_date')]) == df_hl[j, df_hl.columns.get_loc('date')]:\\n#            df.iloc[i,df.columns.get_loc('holiday')]  = 1\\n#df\\n\\n\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import holidays\n",
    "hl_list       = holidays.CA(years=[2018,2019,2020,2021], prov = 'AB').items()\n",
    "df_hl         = pd.DataFrame(hl_list)\n",
    "df_hl.columns = ['date','title']\n",
    "df_hl['date'] = pd.to_datetime(df_hl['date'])\n",
    "#df_hl         = df_hl.sort_values('date')\n",
    "df_hl['date'] = df_hl['date'].dt.date\n",
    "df_hl\n",
    "\n",
    "#df['holiday'] = 0\n",
    "#pd.to_datetime(df.iloc[i,df.columns.get_loc('just_date')]) == df_hl[j, df_hl.columns.get_loc('date')]\n",
    "\n",
    "#for i in range(0, df.shape[0]):\n",
    "#    for j in range(0,df_hl.shape[0]):\n",
    "#        if pd.to_datetime(df.iloc[i,df.columns.get_loc('just_date')]) == df_hl[j, df_hl.columns.get_loc('date')]:\n",
    "#            df.iloc[i,df.columns.get_loc('holiday')]  = 1\n",
    "#df\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "wVDF1099CQro",
    "outputId": "e67eaf89-3462-4b9f-9e08-e0bdfa988fc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['monday_holiday']    = df['monday'] * df['holiday']\\ndf['tuesday_holiday']   = df['tuesday']* df['holiday'] \\ndf['wednesday_holiday'] = df['wednesday'] * df['holiday']\\ndf['thursday_holiday']  = df['thursday'] * df['holiday']\\ndf['friday_holiday']    = df['friday'] * df['holiday']\\ndf['weekend_holiday'] = df['weekend'] * df['holiday']\\n\\n\\ndf['month0_mondayholiday'] = df['month_0']*df['monday_holiday']\\ndf['month1_mondayholiday'] = df['month_1']*df['monday_holiday']\\ndf['month2_mondayholiday'] = df['month_2']*df['monday_holiday']\\ndf['month3_mondayholiday'] = df['month_3']*df['monday_holiday']\\ndf['month4_mondayholiday'] = df['month_4']*df['monday_holiday']\\ndf['month5_mondayholiday'] = df['month_5']*df['monday_holiday']\\ndf['month6_mondayholiday'] = df['month_6']*df['monday_holiday']\\ndf['month7_mondayholiday'] = df['month_7']*df['monday_holiday']\\ndf['month8_mondayholiday'] = df['month_8']*df['monday_holiday']\\ndf['month9_mondayholiday'] = df['month_9']*df['monday_holiday']\\ndf['month10_mondayholiday'] = df['month_10']*df['monday_holiday']\\ndf['month11_mondayholiday'] = df['month_11']*df['monday_holiday']\\n\\ndf['month0_fridayholiday'] = df['month_0']*df['friday_holiday']\\ndf['month1_fridayholiday'] = df['month_1']*df['friday_holiday']\\ndf['month2_fridayholiday'] = df['month_2']*df['friday_holiday']\\ndf['month3_fridayholiday'] = df['month_3']*df['friday_holiday']\\ndf['month4_fridayholiday'] = df['month_4']*df['friday_holiday']\\ndf['month5_fridayholiday'] = df['month_5']*df['friday_holiday']\\ndf['month6_fridayholiday'] = df['month_6']*df['friday_holiday']\\ndf['month7_fridayholiday'] = df['month_7']*df['friday_holiday']\\ndf['month8_fridayholiday'] = df['month_8']*df['friday_holiday']\\ndf['month9_fridayholiday'] = df['month_9']*df['friday_holiday']\\ndf['month10_fridayholiday'] = df['month_10']*df['friday_holiday']\\ndf['month11_fridayholiday'] = df['month_11']*df['friday_holiday']\\n\\ndf['sunlight_mondayholiday']  = df['sunlight_avaialbility']*df['monday_holiday']\\ndf['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['tuesday_holiday']\\ndf['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['wednesday_holiday']\\ndf['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['thursday_holiday']\\ndf['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['friday_holiday']\\n\\ndf\\n\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df['monday_holiday']    = df['monday'] * df['holiday']\n",
    "df['tuesday_holiday']   = df['tuesday']* df['holiday'] \n",
    "df['wednesday_holiday'] = df['wednesday'] * df['holiday']\n",
    "df['thursday_holiday']  = df['thursday'] * df['holiday']\n",
    "df['friday_holiday']    = df['friday'] * df['holiday']\n",
    "df['weekend_holiday'] = df['weekend'] * df['holiday']\n",
    "\n",
    "\n",
    "df['month0_mondayholiday'] = df['month_0']*df['monday_holiday']\n",
    "df['month1_mondayholiday'] = df['month_1']*df['monday_holiday']\n",
    "df['month2_mondayholiday'] = df['month_2']*df['monday_holiday']\n",
    "df['month3_mondayholiday'] = df['month_3']*df['monday_holiday']\n",
    "df['month4_mondayholiday'] = df['month_4']*df['monday_holiday']\n",
    "df['month5_mondayholiday'] = df['month_5']*df['monday_holiday']\n",
    "df['month6_mondayholiday'] = df['month_6']*df['monday_holiday']\n",
    "df['month7_mondayholiday'] = df['month_7']*df['monday_holiday']\n",
    "df['month8_mondayholiday'] = df['month_8']*df['monday_holiday']\n",
    "df['month9_mondayholiday'] = df['month_9']*df['monday_holiday']\n",
    "df['month10_mondayholiday'] = df['month_10']*df['monday_holiday']\n",
    "df['month11_mondayholiday'] = df['month_11']*df['monday_holiday']\n",
    "\n",
    "df['month0_fridayholiday'] = df['month_0']*df['friday_holiday']\n",
    "df['month1_fridayholiday'] = df['month_1']*df['friday_holiday']\n",
    "df['month2_fridayholiday'] = df['month_2']*df['friday_holiday']\n",
    "df['month3_fridayholiday'] = df['month_3']*df['friday_holiday']\n",
    "df['month4_fridayholiday'] = df['month_4']*df['friday_holiday']\n",
    "df['month5_fridayholiday'] = df['month_5']*df['friday_holiday']\n",
    "df['month6_fridayholiday'] = df['month_6']*df['friday_holiday']\n",
    "df['month7_fridayholiday'] = df['month_7']*df['friday_holiday']\n",
    "df['month8_fridayholiday'] = df['month_8']*df['friday_holiday']\n",
    "df['month9_fridayholiday'] = df['month_9']*df['friday_holiday']\n",
    "df['month10_fridayholiday'] = df['month_10']*df['friday_holiday']\n",
    "df['month11_fridayholiday'] = df['month_11']*df['friday_holiday']\n",
    "\n",
    "df['sunlight_mondayholiday']  = df['sunlight_avaialbility']*df['monday_holiday']\n",
    "df['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['tuesday_holiday']\n",
    "df['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['wednesday_holiday']\n",
    "df['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['thursday_holiday']\n",
    "df['sunlight_tuesdayholiday'] = df['sunlight_avaialbility']*df['friday_holiday']\n",
    "\n",
    "df\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "svNuxxIJCQrp"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"training_data_2018_2020_feb_13_20201.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "alberta_training_data_creation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
