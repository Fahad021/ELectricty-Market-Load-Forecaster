{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AIL</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>off_peak</th>\n",
       "      <th>on_peak</th>\n",
       "      <th>just_date</th>\n",
       "      <th>day</th>\n",
       "      <th>sin.day</th>\n",
       "      <th>cos.day</th>\n",
       "      <th>sin.hour</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>sunlight_avaialbility</th>\n",
       "      <th>AIL_previous_hour</th>\n",
       "      <th>AIL_24h_lagged</th>\n",
       "      <th>AIL_2day_lagged</th>\n",
       "      <th>AIL_3day_lagged</th>\n",
       "      <th>AIL_4day_lagged</th>\n",
       "      <th>AIL_5day_lagged</th>\n",
       "      <th>AIL_6day_lagged</th>\n",
       "      <th>AIL_oneweek_lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>10571.0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>10221.0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>10082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>10082.0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>9949.0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719174</td>\n",
       "      <td>0.694830</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27283</th>\n",
       "      <td>2021-02-10 19:00:00</td>\n",
       "      <td>11485.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>11665.0</td>\n",
       "      <td>11598.0</td>\n",
       "      <td>11513.0</td>\n",
       "      <td>11271.0</td>\n",
       "      <td>11326.0</td>\n",
       "      <td>11298.0</td>\n",
       "      <td>11165.0</td>\n",
       "      <td>10961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27284</th>\n",
       "      <td>2021-02-10 20:00:00</td>\n",
       "      <td>11364.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>11485.0</td>\n",
       "      <td>11490.0</td>\n",
       "      <td>11390.0</td>\n",
       "      <td>11127.0</td>\n",
       "      <td>11235.0</td>\n",
       "      <td>11178.0</td>\n",
       "      <td>11057.0</td>\n",
       "      <td>10887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>2021-02-10 21:00:00</td>\n",
       "      <td>11195.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>11364.0</td>\n",
       "      <td>11410.0</td>\n",
       "      <td>11283.0</td>\n",
       "      <td>11093.0</td>\n",
       "      <td>11181.0</td>\n",
       "      <td>11018.0</td>\n",
       "      <td>10860.0</td>\n",
       "      <td>10725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27286</th>\n",
       "      <td>2021-02-10 22:00:00</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>11195.0</td>\n",
       "      <td>11192.0</td>\n",
       "      <td>11148.0</td>\n",
       "      <td>10958.0</td>\n",
       "      <td>11030.0</td>\n",
       "      <td>10811.0</td>\n",
       "      <td>10590.0</td>\n",
       "      <td>10524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27287</th>\n",
       "      <td>2021-02-10 23:00:00</td>\n",
       "      <td>10839.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>0.996832</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>10974.0</td>\n",
       "      <td>10944.0</td>\n",
       "      <td>10737.0</td>\n",
       "      <td>10807.0</td>\n",
       "      <td>10605.0</td>\n",
       "      <td>10334.0</td>\n",
       "      <td>10261.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27288 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datetime      AIL  hour_of_day  off_peak  on_peak  \\\n",
       "0      2018-01-01 00:00:00  10221.0            0         1        0   \n",
       "1      2018-01-01 01:00:00  10082.0            1         1        0   \n",
       "2      2018-01-01 02:00:00   9949.0            2         1        0   \n",
       "3      2018-01-01 03:00:00   9886.0            3         1        0   \n",
       "4      2018-01-01 04:00:00   9930.0            4         1        0   \n",
       "...                    ...      ...          ...       ...      ...   \n",
       "27283  2021-02-10 19:00:00  11485.0           19         0        1   \n",
       "27284  2021-02-10 20:00:00  11364.0           20         1        0   \n",
       "27285  2021-02-10 21:00:00  11195.0           21         1        0   \n",
       "27286  2021-02-10 22:00:00  10961.0           22         1        0   \n",
       "27287  2021-02-10 23:00:00  10839.0           23         1        0   \n",
       "\n",
       "        just_date  day   sin.day   cos.day  sin.hour  ...  year  \\\n",
       "0      2018-01-01    1  0.719174  0.694830  0.000000  ...  2018   \n",
       "1      2018-01-01    1  0.719174  0.694830  0.258819  ...  2018   \n",
       "2      2018-01-01    1  0.719174  0.694830  0.500000  ...  2018   \n",
       "3      2018-01-01    1  0.719174  0.694830  0.707107  ...  2018   \n",
       "4      2018-01-01    1  0.719174  0.694830  0.866025  ...  2018   \n",
       "...           ...  ...       ...       ...       ...  ...   ...   \n",
       "27283  2021-02-10   41  0.996832  0.079532 -0.965926  ...  2021   \n",
       "27284  2021-02-10   41  0.996832  0.079532 -0.866025  ...  2021   \n",
       "27285  2021-02-10   41  0.996832  0.079532 -0.707107  ...  2021   \n",
       "27286  2021-02-10   41  0.996832  0.079532 -0.500000  ...  2021   \n",
       "27287  2021-02-10   41  0.996832  0.079532 -0.258819  ...  2021   \n",
       "\n",
       "       sunlight_avaialbility  AIL_previous_hour  AIL_24h_lagged  \\\n",
       "0                          0            10571.0         10221.0   \n",
       "1                          0            10221.0         10082.0   \n",
       "2                          0            10082.0          9949.0   \n",
       "3                          0             9949.0          9886.0   \n",
       "4                          0             9886.0          9930.0   \n",
       "...                      ...                ...             ...   \n",
       "27283                      0            11665.0         11598.0   \n",
       "27284                      0            11485.0         11490.0   \n",
       "27285                      0            11364.0         11410.0   \n",
       "27286                      0            11195.0         11192.0   \n",
       "27287                      0            10961.0         10974.0   \n",
       "\n",
       "       AIL_2day_lagged  AIL_3day_lagged  AIL_4day_lagged  AIL_5day_lagged  \\\n",
       "0              10221.0          10221.0          10221.0          10221.0   \n",
       "1              10082.0          10082.0          10082.0          10082.0   \n",
       "2               9949.0           9949.0           9949.0           9949.0   \n",
       "3               9886.0           9886.0           9886.0           9886.0   \n",
       "4               9930.0           9930.0           9930.0           9930.0   \n",
       "...                ...              ...              ...              ...   \n",
       "27283          11513.0          11271.0          11326.0          11298.0   \n",
       "27284          11390.0          11127.0          11235.0          11178.0   \n",
       "27285          11283.0          11093.0          11181.0          11018.0   \n",
       "27286          11148.0          10958.0          11030.0          10811.0   \n",
       "27287          10944.0          10737.0          10807.0          10605.0   \n",
       "\n",
       "       AIL_6day_lagged  AIL_oneweek_lagged  \n",
       "0              10221.0             10221.0  \n",
       "1              10082.0             10082.0  \n",
       "2               9949.0              9949.0  \n",
       "3               9886.0              9886.0  \n",
       "4               9930.0              9930.0  \n",
       "...                ...                 ...  \n",
       "27283          11165.0             10961.0  \n",
       "27284          11057.0             10887.0  \n",
       "27285          10860.0             10725.0  \n",
       "27286          10590.0             10524.0  \n",
       "27287          10334.0             10261.0  \n",
       "\n",
       "[27288 rows x 65 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('training_data_2018_2020_feb_13_20201.csv').iloc[:,1:66]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'AIL', 'hour_of_day', 'off_peak', 'on_peak', 'just_date',\n",
       "       'day', 'sin.day', 'cos.day', 'sin.hour', 'cos.hour', 'weekend',\n",
       "       'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday',\n",
       "       'sunday', 'month_0', 'month_1', 'month_2', 'month_3', 'month_4',\n",
       "       'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10',\n",
       "       'month_11', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5',\n",
       "       'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
       "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
       "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'year',\n",
       "       'sunlight_avaialbility', 'AIL_previous_hour', 'AIL_24h_lagged',\n",
       "       'AIL_2day_lagged', 'AIL_3day_lagged', 'AIL_4day_lagged',\n",
       "       'AIL_5day_lagged', 'AIL_6day_lagged', 'AIL_oneweek_lagged'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:28,  3.45trial/s, best loss: inf]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:70: RuntimeWarning: overflow encountered in cosh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:40<00:00,  5.80s/trial, best loss: 436063.6158290594]\n",
      "{'colsample_bytree': 0.8207757988334056, 'gamma': 0.76701931974563, 'max_depth': 3.0, 'min_child_weight': 4.0, 'n_estimators': 696.8672983981303, 'reg_alpha': 2.0, 'reg_lambda': 0.9899167896435772}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "df = df.interpolate(method='nearest').ffill().bfill()\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#file_name   =  \"feature_v2.pkl\"\n",
    "#open_file   =  open(file_name, \"rb\")\n",
    "#loaded_list =  pickle.load(open_file)\n",
    "#open_file.close()\n",
    "\n",
    "df_hypopt       = df\n",
    "split_date      = '2020-01-01 00:00:00'\n",
    "df_hypopt_train = df_hypopt.loc[df_hypopt.Datetime < split_date].copy()\n",
    "df_hypopt_test  = df_hypopt.loc[df_hypopt.Datetime >= split_date].copy()\n",
    "\n",
    "y_train         = df_hypopt_train['AIL'].values\n",
    "y_test          = df_hypopt_test['AIL'].values\n",
    "X_train         = df_hypopt_train.drop(['Datetime', 'AIL', 'just_date'], axis = 1).values\n",
    "X_test          = df_hypopt_test.drop (['Datetime', 'AIL', 'just_date'], axis = 1).values\n",
    "\n",
    "\n",
    "\n",
    "space={ 'max_depth'        : hp.quniform(\"max_depth\", 2, 12, 1),\n",
    "        'gamma'            : hp.uniform ('gamma', 0,1),\n",
    "        'reg_alpha'        : hp.quniform('reg_alpha', 0,2,1),\n",
    "        'reg_lambda'       : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 7, 1),\n",
    "        'n_estimators'     : hp.uniform('n_estimators', 10, 800)\n",
    "    }\n",
    "\n",
    "\n",
    "#def mape(pred, true):\n",
    "#    return np.abs(np.asarray(pred) - np.asarray(true)) / np.maximum(np.abs(np.assarry(true))\n",
    "\n",
    "delta = 10 #huber-delta\n",
    "\n",
    "def optimize (space):\n",
    "    model=XGBRegressor(\n",
    "                       n_estimators     = int(space['n_estimators']), \n",
    "                       max_depth        = int(space['max_depth']),\n",
    "                       gamma            = space['gamma'],\n",
    "                       reg_alpha        = int(space['reg_alpha']),\n",
    "                       min_child_weight = space['min_child_weight'],\n",
    "                       colsample_bytree = space['colsample_bytree'])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    # summarize performance\n",
    "    preds     = model.predict(X_test)\n",
    "    #mae       = mean_absolute_error(y_test, preds)\n",
    "    #loss = np.where(np.abs(y_test - preds) < delta, \n",
    "    #                0.5*((y_test - preds)**2),\n",
    "    #                delta*np.abs(y_test-preds) - 0.5*(delta**2)\n",
    "    #               )\n",
    "    loss = np.log(np.cosh(preds- y_test))\n",
    "    return np.sum(loss)\n",
    "    \n",
    "trials = Trials()\n",
    "result = fmin(\n",
    "            fn        = optimize,\n",
    "            space     = space,\n",
    "            algo      = tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials    = trials\n",
    ")\n",
    "\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.731405857055986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_generated_on_13_2_2021_v6_non_holiday_huber_loss.joblib.dat']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from joblib import dump\n",
    "\n",
    "column_list = ['hour_of_day', 'off_peak', 'on_peak', \n",
    "       'day', 'sin.day', 'cos.day', 'sin.hour', 'cos.hour', 'weekend',\n",
    "       'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday',\n",
    "       'sunday', 'month_0', 'month_1', 'month_2', 'month_3', 'month_4',\n",
    "       'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10',\n",
    "       'month_11', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5',\n",
    "       'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
    "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
    "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'year',\n",
    "       'sunlight_avaialbility', 'AIL_previous_hour', 'AIL_24h_lagged',\n",
    "       'AIL_2day_lagged', 'AIL_3day_lagged', 'AIL_4day_lagged',\n",
    "       'AIL_5day_lagged', 'AIL_6day_lagged', 'AIL_oneweek_lagged' ]\n",
    "\n",
    "df_final = pd.DataFrame(data = df)\n",
    "df_final = df_final.interpolate(method='nearest').ffill().bfill()\n",
    "\n",
    "y_train = pd.DataFrame(df, columns = ['AIL'])\n",
    "y_train = y_train.values\n",
    "X_train = pd.DataFrame(df, columns = column_list)\n",
    "X_train = X_train.values\n",
    "\n",
    "'''\n",
    "mae loss: 'colsample_bytree': 0.9109339305529397, 'gamma': 0.6461068249891915, 'max_depth': 3.0, 'min_child_weight': 5.0, \n",
    "'n_estimators': 717.5962834481896, 'reg_alpha': 2.0, 'reg_lambda': 0.8878703412755587}\n",
    "'''\n",
    "'''\n",
    "huber_loss:\n",
    "\n",
    "'colsample_bytree': 0.7992205992647909, 'gamma': 0.5783448371612743, 'max_depth': 3.0, \n",
    "'min_child_weight': 2.0, 'n_estimators': 739.331766781355,\n",
    "'reg_alpha': 2.0, 'reg_lambda': 0.7732711356862325\n",
    "\n",
    "'''\n",
    "\n",
    "model   = XGBRegressor(colsample_bytree = 0.7992205992647909, \n",
    "                       gamma            = 0.5783448371612743, \n",
    "                       max_depth        = 3, \n",
    "                       min_child_weight = 2, \n",
    "                       n_estimators     = 739, \n",
    "                       reg_alpha        = 2, \n",
    "                       reg_lambda       = 0.7732711356862325)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_train)\n",
    "print(mean_absolute_error(y_train, preds))\n",
    "\n",
    "# save model to file\n",
    "model_name = 'model_generated_on_{}_{}_{}_v6_non_holiday_huber_loss.joblib.dat'.format(datetime.now().day, datetime.now().month, datetime.now().year)\n",
    "joblib.dump(model, filename = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.07s/trial, best loss: 333.83103919971103]\n",
      " 50%|█████     | 1/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.12trial/s, best loss: 333.83103919971103]\n",
      " 67%|██████▋   | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.11s/trial, best loss: 333.83103919971103]\n",
      " 75%|███████▌  | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.43s/trial, best loss: 202.5830185666464]\n",
      " 80%|████████  | 4/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.40trial/s, best loss: 202.5830185666464]\n",
      " 83%|████████▎ | 5/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:19<00:00,  3.30s/trial, best loss: 202.5830185666464]\n",
      " 86%|████████▌ | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:09<00:00,  1.39s/trial, best loss: 141.01354740467085]\n",
      " 88%|████████▊ | 7/8 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:30<00:00,  3.75s/trial, best loss: 141.01354740467085]\n",
      " 89%|████████▉ | 8/9 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:06<00:00,  1.40trial/s, best loss: 141.01354740467085]\n",
      " 90%|█████████ | 9/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.00s/trial, best loss: 141.01354740467085]\n",
      " 91%|█████████ | 10/11 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:30<00:00,  2.73s/trial, best loss: 141.01354740467085]\n",
      " 92%|█████████▏| 11/12 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 72.94trial/s, best loss: 141.01354740467085]\n",
      " 92%|█████████▏| 12/13 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:06<00:00,  1.99trial/s, best loss: 116.76461378257811]\n",
      " 93%|█████████▎| 13/14 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:30<00:00,  2.15s/trial, best loss: 116.76461378257811]\n",
      " 93%|█████████▎| 14/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00,  9.85trial/s, best loss: 116.76461378257811]\n",
      " 94%|█████████▍| 15/16 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.84trial/s, best loss: 116.76461378257811]\n",
      " 94%|█████████▍| 16/17 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00, 13.97trial/s, best loss: 116.76461378257811]\n",
      " 94%|█████████▍| 17/18 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:11<00:00,  1.53trial/s, best loss: 116.76461378257811]\n",
      " 95%|█████████▍| 18/19 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:13<00:00,  1.44trial/s, best loss: 57.0328007954641]\n",
      " 95%|█████████▌| 19/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.50s/trial, best loss: 57.0328007954641]\n",
      " 95%|█████████▌| 20/21 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 18.90trial/s, best loss: 57.0328007954641]\n",
      " 95%|█████████▌| 21/22 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 17.06trial/s, best loss: 57.0328007954641]\n",
      " 96%|█████████▌| 22/23 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 42.56trial/s, best loss: 57.0328007954641]\n",
      " 96%|█████████▌| 23/24 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 22.28trial/s, best loss: 57.0328007954641]\n",
      " 96%|█████████▌| 24/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.62trial/s, best loss: 57.0328007954641]\n",
      " 96%|█████████▌| 25/26 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 47.83trial/s, best loss: 57.0328007954641]\n",
      " 96%|█████████▋| 26/27 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:03<00:00,  8.64trial/s, best loss: 57.0328007954641]\n",
      " 96%|█████████▋| 27/28 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.95trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 28/29 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  8.06trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 29/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 20.76trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 30/31 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 17.31trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 31/32 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:06<00:00,  5.14trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 32/33 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:30<00:00,  1.10trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 33/34 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:10<00:00,  3.39trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 34/35 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 29.04trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 35/36 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:01<00:00, 25.91trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 36/37 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:30<00:00,  1.23trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 37/38 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:10<00:00,  3.76trial/s, best loss: 57.0328007954641]\n",
      " 97%|█████████▋| 38/39 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:01<00:00, 30.17trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 39/40 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  9.62trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 40/41 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 20.86trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 41/42 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 50.96trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 42/43 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:30<00:00,  1.43trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 43/44 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 83.87trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 44/45 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:21<00:00,  2.11trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 45/46 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:28<00:00,  1.60trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 46/47 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:02<00:00, 15.68trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 47/48 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 122.08trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 48/49 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:30<00:00,  1.63trial/s, best loss: 57.0328007954641]\n",
      " 98%|█████████▊| 49/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.27trial/s, best loss: 57.0328007954641]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abulhasanfahad/opt/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:309: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.991\n",
      "{'learner': GradientBoostingRegressor(learning_rate=0.32941608891734564, max_depth=None,\n",
      "                          n_estimators=45, presort='auto', random_state=3,\n",
      "                          subsample=0.7719952128201714), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from   xgboost import XGBRegressor\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "#from   matplotlib import pyplot as plt\n",
    "#from   sklearn.model_selection import train_test_split\n",
    "#from   sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn\n",
    "from   datetime import datetime\n",
    "import pickle\n",
    "import hyperopt\n",
    "from   hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from   sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from   hpsklearn import HyperoptEstimator, any_preprocessing, any_regressor\n",
    "from hpsklearn import gradient_boosting_regression\n",
    "\n",
    "from   hyperopt import tpe\n",
    "\n",
    "\n",
    "df = df.interpolate(method='nearest').ffill().bfill()\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#file_name   =  \"feature_v2.pkl\"\n",
    "#open_file   =  open(file_name, \"rb\")\n",
    "#loaded_list =  pickle.load(open_file)\n",
    "#open_file.close()\n",
    "\n",
    "df_hypopt       = df\n",
    "split_date      = '2020-01-01 00:00:00'\n",
    "df_hypopt_train = df_hypopt.loc[df_hypopt.Datetime < split_date].copy()\n",
    "df_hypopt_test  = df_hypopt.loc[df_hypopt.Datetime >= split_date].copy()\n",
    "\n",
    "y_train         = df_hypopt_train['AIL'].values\n",
    "y_test          = df_hypopt_test['AIL'].values\n",
    "X_train         = df_hypopt_train.drop(['Datetime', 'AIL', 'just_date'], axis = 1).values\n",
    "X_test          = df_hypopt_test.drop (['Datetime', 'AIL', 'just_date'], axis = 1).values\n",
    "\n",
    "\n",
    "# define search\n",
    "model = HyperoptEstimator(regressor     = gradient_boosting_regression('gbr'), \n",
    "                          preprocessing = any_preprocessing('pre'), \n",
    "                          loss_fn       = mean_absolute_error, \n",
    "                          algo          = tpe.suggest, \n",
    "                          max_evals     = 50, \n",
    "                          trial_timeout  = 30)\n",
    "# perform the search\n",
    "model.fit(X_train, y_train)\n",
    "# summarize performance\n",
    "mae = model.score(X_test, y_test)\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "# summarize the best model\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
