{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AIL</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>just_date</th>\n",
       "      <th>day</th>\n",
       "      <th>hour_x_day</th>\n",
       "      <th>sin.day</th>\n",
       "      <th>cos.day</th>\n",
       "      <th>sin.hour</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_ftmcmry</th>\n",
       "      <th>wind_ftmcmry</th>\n",
       "      <th>temp_lthbrg</th>\n",
       "      <th>wind_lthbrg</th>\n",
       "      <th>temp_mdcnht</th>\n",
       "      <th>wind_mdcnht</th>\n",
       "      <th>temp_rddr</th>\n",
       "      <th>wind_rddr</th>\n",
       "      <th>temp_slvlk</th>\n",
       "      <th>wind_slvlk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>10008.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.1</td>\n",
       "      <td>11</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>9868.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>9736.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>9597.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-14.1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18505</th>\n",
       "      <td>2021-02-10 19:00:00</td>\n",
       "      <td>11485.0</td>\n",
       "      <td>18524</td>\n",
       "      <td>19</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>779</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18506</th>\n",
       "      <td>2021-02-10 20:00:00</td>\n",
       "      <td>11364.0</td>\n",
       "      <td>18525</td>\n",
       "      <td>20</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>820</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18507</th>\n",
       "      <td>2021-02-10 21:00:00</td>\n",
       "      <td>11195.0</td>\n",
       "      <td>18526</td>\n",
       "      <td>21</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>861</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>2021-02-10 22:00:00</td>\n",
       "      <td>10961.0</td>\n",
       "      <td>18527</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>902</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18509</th>\n",
       "      <td>2021-02-10 23:00:00</td>\n",
       "      <td>10839.0</td>\n",
       "      <td>18528</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>41</td>\n",
       "      <td>943</td>\n",
       "      <td>0.648630</td>\n",
       "      <td>0.761104</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18510 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datetime      AIL  trend  hour_of_day   just_date  day  \\\n",
       "0      2019-01-01 00:00:00  10008.0      1            0  2019-01-01    1   \n",
       "1      2019-01-01 01:00:00   9868.0      2            1  2019-01-01    1   \n",
       "2      2019-01-01 02:00:00   9736.0      3            2  2019-01-01    1   \n",
       "3      2019-01-01 03:00:00   9597.0      4            3  2019-01-01    1   \n",
       "4      2019-01-01 04:00:00   9530.0      5            4  2019-01-01    1   \n",
       "...                    ...      ...    ...          ...         ...  ...   \n",
       "18505  2021-02-10 19:00:00  11485.0  18524           19  2021-02-10   41   \n",
       "18506  2021-02-10 20:00:00  11364.0  18525           20  2021-02-10   41   \n",
       "18507  2021-02-10 21:00:00  11195.0  18526           21  2021-02-10   41   \n",
       "18508  2021-02-10 22:00:00  10961.0  18527           22  2021-02-10   41   \n",
       "18509  2021-02-10 23:00:00  10839.0  18528           23  2021-02-10   41   \n",
       "\n",
       "       hour_x_day   sin.day   cos.day  sin.hour  ...  temp_ftmcmry  \\\n",
       "0               0  0.017213  0.999852  0.000000  ...         -18.1   \n",
       "1               1  0.017213  0.999852  0.258819  ...         -17.0   \n",
       "2               2  0.017213  0.999852  0.500000  ...         -15.2   \n",
       "3               3  0.017213  0.999852  0.707107  ...         -13.2   \n",
       "4               4  0.017213  0.999852  0.866025  ...         -11.5   \n",
       "...           ...       ...       ...       ...  ...           ...   \n",
       "18505         779  0.648630  0.761104 -0.965926  ...         -29.0   \n",
       "18506         820  0.648630  0.761104 -0.866025  ...         -30.0   \n",
       "18507         861  0.648630  0.761104 -0.707107  ...         -31.0   \n",
       "18508         902  0.648630  0.761104 -0.500000  ...         -32.0   \n",
       "18509         943  0.648630  0.761104 -0.258819  ...         -33.0   \n",
       "\n",
       "       wind_ftmcmry  temp_lthbrg  wind_lthbrg  temp_mdcnht  wind_mdcnht  \\\n",
       "0                11        -11.8          NaN        -12.4          NaN   \n",
       "1                 9        -10.7          NaN        -12.5          NaN   \n",
       "2                 8         -8.5          NaN        -11.8          NaN   \n",
       "3                12         -6.7          NaN        -10.6          NaN   \n",
       "4                 9         -3.6          NaN         -8.1          NaN   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "18505            20        -27.0         20.0        -27.0         20.0   \n",
       "18506            20        -28.0         20.0        -28.0         20.0   \n",
       "18507            10        -31.0         10.0        -29.0         10.0   \n",
       "18508            10        -31.0         10.0        -29.0         10.0   \n",
       "18509            10        -32.0         10.0        -30.0         10.0   \n",
       "\n",
       "       temp_rddr  wind_rddr  temp_slvlk  wind_slvlk  \n",
       "0          -15.2       11.0       -14.4         8.0  \n",
       "1          -13.3        5.0       -13.6         5.0  \n",
       "2          -11.8       13.0       -12.9         5.0  \n",
       "3          -10.2       14.0       -14.1         5.0  \n",
       "4           -8.8       17.0       -12.2         5.0  \n",
       "...          ...        ...         ...         ...  \n",
       "18505      -30.0       20.0       -26.0        10.0  \n",
       "18506      -31.0       20.0       -27.0        10.0  \n",
       "18507      -32.0       10.0       -28.0        10.0  \n",
       "18508      -33.0       10.0       -29.0        10.0  \n",
       "18509      -34.0       10.0       -30.0        10.0  \n",
       "\n",
       "[18510 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('new_training_data_v7_2019_2020_feb_13_20201.csv').iloc[:,1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'AIL', 'trend', 'hour_of_day', 'just_date', 'day',\n",
       "       'hour_x_day', 'sin.day', 'cos.day', 'sin.hour', 'cos.hour', 'sin.trend',\n",
       "       'cos.trend', 'weekend', 'month', 'year', 'sunlight_avaialbility',\n",
       "       'AIL_previous_hour', 'AIL_24h_lagged', 'AIL_2day_lagged',\n",
       "       'AIL_3day_lagged', 'AIL_4day_lagged', 'AIL_5day_lagged',\n",
       "       'AIL_6day_lagged', 'AIL_oneweek_lagged', 'temp_calgary', 'wind_calgary',\n",
       "       'temp_edmonton', 'wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
       "       'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', 'temp_rddr',\n",
       "       'wind_rddr', 'temp_slvlk', 'wind_slvlk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3936346511496772, test loss: 0.5312996313153983\n",
      "train loss: 0.25245131271261656, test loss: 0.8079168888929069                   \n",
      "train loss: 0.11889135528341763, test loss: 0.5473135624617612                   \n",
      "train loss: 0.10515425391361523, test loss: 0.7515181684802513                   \n",
      "train loss: 0.4674760874545175, test loss: 0.8157116094736137                    \n",
      "train loss: 0.08077335767410031, test loss: 0.5466716889724497                   \n",
      "train loss: 0.21388734543484356, test loss: 0.5150398700774598                   \n",
      "train loss: 0.16499392080109473, test loss: 0.5677777942000803                   \n",
      "train loss: 0.5261921857477716, test loss: 0.5944940389102646                    \n",
      "train loss: 0.4891950504240333, test loss: 0.5581636866229243                    \n",
      "train loss: 0.05503962033318045, test loss: 0.6694194767422248                    \n",
      "train loss: 0.10159519147949932, test loss: 0.5371787330529598                    \n",
      "train loss: 0.4938098085175524, test loss: 0.5885566037369344                     \n",
      "train loss: 0.007627348717749252, test loss: 0.5589413416605078                   \n",
      "train loss: 0.2201789819022237, test loss: 0.6033063183692263                     \n",
      "train loss: 0.26372097152835194, test loss: 0.5316776103071656                    \n",
      "train loss: 0.2659757939115032, test loss: 0.672794930385198                      \n",
      "train loss: 0.04851412978653336, test loss: 0.5546890742807146                    \n",
      "train loss: 0.27267633811079217, test loss: 0.5360647979039959                    \n",
      "train loss: 0.1454525677837263, test loss: 0.558399297310122                      \n",
      "train loss: 0.33154041387923316, test loss: 0.5145151461815805                    \n",
      "train loss: 0.3333041205182924, test loss: 0.5151835718086271                     \n",
      "train loss: 0.37071168964287243, test loss: 0.5272272239160328                    \n",
      "train loss: 0.07477022653973531, test loss: 0.5296391762258423                    \n",
      "train loss: 0.37804375011423685, test loss: 0.5191284850665725                    \n",
      "train loss: 0.37391623145493996, test loss: 0.5170825365319234                    \n",
      "train loss: 0.26308008900676355, test loss: 0.4999015995906774                    \n",
      "train loss: 0.4173088145757763, test loss: 0.5287751842851061                     \n",
      "train loss: 0.46658508007683475, test loss: 0.5974738511399615                    \n",
      "train loss: 0.5536885330200908, test loss: 0.6615530809991931                     \n",
      "train loss: 0.3978186236999424, test loss: 0.5339357920041138                     \n",
      "train loss: 0.0906094338291748, test loss: 0.530765182929981                      \n",
      "train loss: 0.19976853369118994, test loss: 0.5183078621541626                    \n",
      "train loss: 0.10272021398263775, test loss: 0.5587417978659747                    \n",
      "train loss: 0.39040615832565834, test loss: 0.5343816370876961                    \n",
      "train loss: 0.23435094964171496, test loss: 0.5011806641081318                    \n",
      "train loss: 0.15012952763442666, test loss: 0.7023922287457147                    \n",
      "train loss: 0.041376656512688806, test loss: 0.5480091741265528                   \n",
      "train loss: 2.102750550574673, test loss: 2.5421914687496394                      \n",
      "train loss: 0.21597909531817333, test loss: 0.5220378447027775                    \n",
      "train loss: 0.13344452032712428, test loss: 0.767396381116301                     \n",
      "train loss: 0.03595013581214408, test loss: 0.5737238891554401                    \n",
      "train loss: 0.5735058896993783, test loss: 0.6399772838384358                     \n",
      "train loss: 0.12702597412658834, test loss: 0.5406966076360303                    \n",
      "train loss: 0.09412380907969235, test loss: 0.5253807098520792                    \n",
      "train loss: 0.20942188163641964, test loss: 0.5283244230124315                    \n",
      "train loss: 0.10373793942500284, test loss: 0.519126032405411                     \n",
      "train loss: 0.51392473468844, test loss: 0.5806255621780213                       \n",
      "train loss: 0.3143099453928106, test loss: 0.5209368049869721                     \n",
      "train loss: 0.002698948169415698, test loss: 0.9400142076937377                   \n",
      "train loss: 0.3204675201660939, test loss: 0.5504456199122034                     \n",
      "train loss: 0.04918319656628486, test loss: 0.5548914900771491                    \n",
      "train loss: 0.07177463117427817, test loss: 0.5638491928275347                    \n",
      "train loss: 0.29280959172776905, test loss: 0.5259243494578092                    \n",
      "train loss: 0.2539028213291989, test loss: 0.521207339428149                      \n",
      "train loss: 0.48603281500467943, test loss: 0.5757783197045774                    \n",
      "train loss: 0.6008675871149214, test loss: 0.6793671396004995                     \n",
      "train loss: 0.17879663612773108, test loss: 0.5072401314115055                    \n",
      "train loss: 0.07770598156872097, test loss: 0.5234732699112968                    \n",
      "train loss: 0.45821458178171065, test loss: 0.5709611575524149                    \n",
      "train loss: 0.6725661588793443, test loss: 0.7876694487217442                     \n",
      "train loss: 0.05852406345458745, test loss: 0.550606093197095                     \n",
      "train loss: 0.2674672558220954, test loss: 0.5000942167647323                     \n",
      "train loss: 0.3040516803353213, test loss: 0.5193032978873664                     \n",
      "train loss: 0.7959086556111401, test loss: 0.9297900523760857                     \n",
      "train loss: 0.2659175487393344, test loss: 0.5144248516895903                     \n",
      "train loss: 0.3557805538037079, test loss: 0.516708747047887                      \n",
      "train loss: 0.24348053863653685, test loss: 0.516385772015757                     \n",
      "train loss: 0.12234194166291555, test loss: 0.5280308835683782                    \n",
      "train loss: 0.22122410092808337, test loss: 0.5123487074894328                    \n",
      "train loss: 0.413014883975791, test loss: 0.5208109349683555                      \n",
      "train loss: 0.35181578652645573, test loss: 0.5206507161706927                    \n",
      "train loss: 0.2529643217503952, test loss: 0.5130775937348243                     \n",
      "train loss: 0.15622578822223102, test loss: 0.5295261161959909                    \n",
      "train loss: 0.23093207427933188, test loss: 0.5012699545649727                    \n",
      "train loss: 0.17125055748156323, test loss: 0.7111143594811796                    \n",
      "train loss: 0.3769201848166353, test loss: 0.52377526692863                       \n",
      "train loss: 0.0650410130226761, test loss: 0.5561311988375344                     \n",
      "train loss: 0.18988381868770382, test loss: 0.5192048043829572                    \n",
      "train loss: 0.4876774276358344, test loss: 0.5901125034723669                     \n",
      "train loss: 0.293153724806921, test loss: 0.5083829782865668                      \n",
      "train loss: 0.3204328673889128, test loss: 0.6313305242931456                     \n",
      "train loss: 0.24907869654482237, test loss: 0.5061920116655849                    \n",
      "train loss: 0.0864583685571705, test loss: 0.523979329746872                      \n",
      "train loss: 0.24847953081000101, test loss: 0.5184969740527963                    \n",
      "train loss: 0.05428768952014974, test loss: 0.5639673243221595                    \n",
      "train loss: 0.40812914142273504, test loss: 0.5277926034398938                    \n",
      "train loss: 0.08164685410593503, test loss: 0.551501435816848                     \n",
      "train loss: 0.40309511162026157, test loss: 0.5474765764241699                    \n",
      "train loss: 0.20650293404432937, test loss: 0.5320510605939177                    \n",
      "train loss: 0.6071971130682382, test loss: 0.7329621611003635                     \n",
      "train loss: 0.5494246532043009, test loss: 0.6216349743437748                     \n",
      "train loss: 0.19702076847954242, test loss: 0.5142820047836059                    \n",
      "train loss: 0.10003456572954723, test loss: 0.5312395367845415                    \n",
      "train loss: 0.28506549013503407, test loss: 0.5149184214333126                    \n",
      "train loss: 0.1726381581242379, test loss: 0.5152096314221606                     \n",
      "train loss: 0.24385967236239264, test loss: 0.5246836482674505                    \n",
      "train loss: 0.09073158774572272, test loss: 0.5760779784418775                    \n",
      "train loss: 0.5735333768181313, test loss: 0.639968795198905                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.34072699801953366, test loss: 0.5060650863387863                    \n",
      "100%|██████████| 100/100 [01:42<00:00,  1.03s/trial, best loss: 0.4999015995906774]\n",
      "{'colsample_bytree': 0.9685405801358924, 'gamma': 0.5534257429319893, 'max_depth': 5.0, 'min_child_weight': 7.0, 'n_estimators': 178.66950947414804, 'reg_alpha': 1.0, 'reg_lambda': 0.48566044877632586}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "#df = df.interpolate(method='nearest').ffill().bfill()\n",
    "#df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#file_name   =  \"feature_v2.pkl\"\n",
    "#open_file   =  open(file_name, \"rb\")\n",
    "#loaded_list =  pickle.load(open_file)\n",
    "#open_file.close()\n",
    "\n",
    "df_hypopt       = df\n",
    "split_date      = '2020-06-01 00:00:00'\n",
    "df_hypopt_train = df_hypopt.loc[df_hypopt.Datetime < split_date].copy()\n",
    "df_hypopt_test  = df_hypopt.loc[df_hypopt.Datetime >= split_date].copy()\n",
    "\n",
    "y_train         = df_hypopt_train['AIL'].values\n",
    "y_test          = df_hypopt_test['AIL'].values\n",
    "X_train         = df_hypopt_train.drop(['Datetime', 'AIL', 'just_date', 'trend', 'sin.trend',\n",
    "                                        'cos.trend','sin.day', 'cos.day', 'sin.hour', 'cos.hour',\n",
    "                                        'wind_calgary', 'wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
    "                                         'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', \n",
    "                                        'temp_rddr','wind_rddr', 'temp_slvlk', 'wind_slvlk'], axis = 1).values\n",
    "\n",
    "X_test          = df_hypopt_test.drop (['Datetime', 'AIL', 'just_date', 'trend', 'sin.trend',\n",
    "                                         'cos.trend','sin.day', 'cos.day', 'sin.hour', 'cos.hour',\n",
    "                                        'wind_calgary','wind_edmonton', 'temp_ftmcmry', 'wind_ftmcmry',\n",
    "                                         'temp_lthbrg', 'wind_lthbrg', 'temp_mdcnht', 'wind_mdcnht', \n",
    "                                        'temp_rddr','wind_rddr', 'temp_slvlk', 'wind_slvlk'], axis = 1).values\n",
    "\n",
    "\n",
    "\n",
    "space={ 'max_depth'        : hp.quniform(\"max_depth\", 2, 12, 1),\n",
    "        'gamma'            : hp.uniform ('gamma', 0,1),\n",
    "        'reg_alpha'        : hp.quniform('reg_alpha', 0,2,1),\n",
    "        'reg_lambda'       : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 7, 1),\n",
    "        'n_estimators'     : hp.uniform('n_estimators', 10, 300)\n",
    "    }\n",
    "\n",
    "\n",
    "#def mape(pred, true):\n",
    "#    return np.abs(np.asarray(pred) - np.asarray(true)) / np.maximum(np.abs(np.assarry(true))\n",
    "\n",
    "delta = 10 #huber-delta\n",
    "\n",
    "def optimize (space):\n",
    "    model=XGBRegressor(\n",
    "                       n_estimators     = int(space['n_estimators']), \n",
    "                       max_depth        = int(space['max_depth']),\n",
    "                       gamma            = space['gamma'],\n",
    "                       reg_alpha        = int(space['reg_alpha']),\n",
    "                       min_child_weight = space['min_child_weight'],\n",
    "                       colsample_bytree = space['colsample_bytree'])\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    train_loss = np.mean(np.abs((y_train - model.predict(X_train)) / y_train)) * 100\n",
    "    # summarize performance\n",
    "    preds     = model.predict(X_test)\n",
    "    #mae       = mean_absolute_error(y_test, preds)\n",
    "    #loss = np.where(np.abs(y_test - preds) < delta, \n",
    "    #                0.5*((y_test - preds)**2),\n",
    "    #                delta*np.abs(y_test-preds) - 0.5*(delta**2)\n",
    "    #               )\n",
    "    loss = np.mean(np.abs((y_test - preds) / y_test)) * 100\n",
    "    print('train loss: {}, test loss: {}'.format(train_loss, loss))\n",
    "    return loss\n",
    "    \n",
    "trials = Trials()\n",
    "result = fmin(\n",
    "            fn        = optimize,\n",
    "            space     = space,\n",
    "            algo      = tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials    = trials\n",
    ")\n",
    "\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.950782755081008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_generated_on_14_2_2021_v8_non_holiday_mape_loss_only_temp.joblib.dat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from joblib import dump\n",
    "\n",
    "column_list = ['hour_of_day',  'day',\n",
    "       'hour_x_day',  'weekend', 'month', 'year', 'sunlight_avaialbility',\n",
    "       'AIL_previous_hour', 'AIL_24h_lagged', 'AIL_2day_lagged',\n",
    "       'AIL_3day_lagged', 'AIL_4day_lagged', 'AIL_5day_lagged',\n",
    "       'AIL_6day_lagged', 'AIL_oneweek_lagged', 'temp_calgary',\n",
    "       'temp_edmonton' ]\n",
    "\n",
    "df_final = pd.DataFrame(data = df)\n",
    "df_final = df_final.interpolate(method='nearest').ffill().bfill()\n",
    "\n",
    "y_train = pd.DataFrame(df, columns = ['AIL'])\n",
    "y_train = y_train.values\n",
    "X_train = pd.DataFrame(df, columns = column_list)\n",
    "X_train = X_train.values\n",
    "\n",
    "\n",
    "'''\n",
    "{'colsample_bytree': 0.9685405801358924, 'gamma': 0.5534257429319893,\n",
    "'max_depth': 5.0, 'min_child_weight': 7.0, \n",
    "'n_estimators': 178.66950947414804, 'reg_alpha': 1.0,\n",
    "'reg_lambda': 0.48566044877632586}\n",
    "'''\n",
    "model   = XGBRegressor(colsample_bytree = 0.9685405801358924, \n",
    "                       gamma            = 0.5589842777690632, \n",
    "                       max_depth        = 5, \n",
    "                       min_child_weight = 7, \n",
    "                       n_estimators     = 179, \n",
    "                       reg_alpha        = 1, \n",
    "                       reg_lambda       = 0.48566044877632)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_train)\n",
    "print(np.mean(np.abs((y_train - preds) / y_train)) * 100)\n",
    "\n",
    "# save model to file\n",
    "model_name = 'model_generated_on_{}_{}_{}_v8_non_holiday_mape_loss_only_temp.joblib.dat'.format(datetime.now().day, datetime.now().month, datetime.now().year)\n",
    "joblib.dump(model, filename = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
